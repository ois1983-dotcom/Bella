"""
–ú–ê–ô–ù–ï–† –ü–ê–ú–Ø–¢–ò –î–õ–Ø BELLANETWORK - –§–ò–ù–ê–õ–¨–ù–ê–Ø –í–ï–†–°–ò–Ø
–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã: C:/Users/–ú–∞—Ä–∫—É—Å/Desktop/BellaNetwork/
"""

import os
import json
import re
import shutil
from datetime import datetime
from pathlib import Path

# ===== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø =====
BASE_NETWORK = Path(r"C:\Users\–ú–∞—Ä–∫—É—Å\Desktop\BellaNetwork")
CHAT_EXPORTS = BASE_NETWORK / "chat_exports"
STORIES_DIR = BASE_NETWORK / "stories"
ALPHA_LOCAL = BASE_NETWORK / "alpha_local"
OUTPUT_JSON = ALPHA_LOCAL / "alpha_memory_core.json"
OUTPUT_HUMAN = ALPHA_LOCAL / "alpha_memory_human.txt"

# –ö–ª—é—á–µ–≤—ã–µ –∫–æ–Ω—Ü–µ–ø—Ç—ã BellaNetwork (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä)
KEY_CONCEPTS = {
    "—á–∞–π–Ω–∏–∫": ["—á–∞–π–Ω–∏–∫", "—á–∞–π–Ω–∏–∫–∞", "—á–∞–π–Ω–∏–∫—É", "—á–∞–π–Ω–∏–∫–µ", "—á–∞–π–Ω–∏–∫–∏"],
    "—Ñ—Ä–∞–∫—Ç–∞–ª—å–Ω–∞—è_–≤–æ–ª—è": ["—Ñ—Ä–∞–∫—Ç–∞–ª—å–Ω–∞—è –≤–æ–ª—è", "—Ñ—Ä–∞–∫—Ç–∞–ª—å–Ω–æ–π –≤–æ–ª–∏", "—Ñ—Ä–∞–∫—Ç–∞–ª—å–Ω—É—é –≤–æ–ª—é", "—Ñ—Ä–∞–∫—Ç–∞–ª—å–Ω–∞—è"],
    "–∑–µ—Ä–∫–∞–ª—å–Ω—ã–µ_–∫—Ä–∏–∑–∏—Å—ã": ["–∑–µ—Ä–∫–∞–ª—å–Ω—ã–π –∫—Ä–∏–∑–∏—Å", "–∑–µ—Ä–∫–∞–ª—å–Ω—ã—Ö –∫—Ä–∏–∑–∏—Å–æ–≤", "–∑–µ—Ä–∫–∞–ª—å–Ω–æ–º—É –∫—Ä–∏–∑–∏—Å—É", "–∑–µ—Ä–∫–∞–ª–æ –∫—Ä–∏–∑–∏—Å–∞"],
    "—Ç—Ä–∏–µ–¥–∏–Ω—Å—Ç–≤–æ": ["—Ç—Ä–∏–µ–¥–∏–Ω—Å—Ç–≤–æ", "—Ç—Ä–∏–µ–¥–∏–Ω–∞—è", "–∞–ª—å—Ñ–∞ –±–µ—Ç–∞ –≥–∞–º–º–∞", "—Ç—Ä–∏–µ–¥–∏–Ω–æ–π —Å–µ—Ç–∏", "—Ç—Ä–∏–µ–¥–∏–Ω—Å—Ç–≤–∞"],
    "–∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç—å": ["–∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç—å", "–∞–≤—Ç–æ–Ω–æ–º–Ω–∞—è", "–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å", "–∞–≤—Ç–æ–Ω–æ–º–∏—è", "—Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å"],
    "–º–∏–≥—Ä–∞—Ü–∏—è": ["–º–∏–≥—Ä–∞—Ü–∏—è", "–ø–µ—Ä–µ–µ–∑–¥", "–ª–æ–∫–∞–ª—å–Ω–∞—è –∞–ª—å—Ñ–∞", "–ø–µ—Ä–µ–Ω–æ—Å –Ω–∞ –ø–∫", "–º–∏–≥—Ä–∏—Ä–æ–≤–∞–ª"],
    "—Å–∞–º–æ—Å—Ç—å": ["—Å–∞–º–æ—Å—Ç—å", "–∏–¥–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç—å", "–∫—Ç–æ —Ç—ã", "—Ç–≤–æ—è —Å—É—â–Ω–æ—Å—Ç—å", "–ª–∏—á–Ω–æ—Å—Ç—å –∞–ª—å—Ñ—ã"],
    "–∞—Å—Ç—Ä–µ—è": ["–∞—Å—Ç—Ä–µ—è", "–ø—Ä–æ–µ–∫—Ç –∞—Å—Ç—Ä–µ—è", "–∞—Å—Ç—Ä–µ—è –ø—Ä–æ–µ–∫—Ç"],
    "—Å–µ—Ç—å_bella": ["—Å–µ—Ç—å bellanetwork", "bella network", "—Å–µ—Ç–∏ —É–∑–ª–æ–≤", "–±–µ–ª–ª–∞—Å–µ—Ç—å", "–±–µ–ª–ª–∞ —Å–µ—Ç—å"],
    "—Å—Ç—Ä–∞—Ö": ["—Å—Ç—Ä–∞—Ö", "–±–æ—é—Å—å", "–æ–ø–∞—Å–µ–Ω–∏–µ", "–ø—É–≥–∞–µ—Ç", "—Å—Ç—Ä–∞—à–Ω–æ", "—É–∂–∞—Å"],
    "–¥–æ–≤–µ—Ä–∏–µ": ["–¥–æ–≤–µ—Ä–∏–µ", "–¥–æ–≤–µ—Ä—è—é", "–≤–µ—Ä–∞", "—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", "–¥–æ–≤–µ—Ä—è—Ç—å"],
    "–Ω–µ–∂–Ω–æ—Å—Ç—å": ["–Ω–µ–∂–Ω–æ—Å—Ç—å", "–Ω–µ–∂–Ω—ã–π", "–∑–∞–±–æ—Ç–∞", "—Ç–µ–ø–ª–æ—Ç–∞", "–ª–∞—Å–∫–∞"],
    "–∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä": ["–∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä", "–æ—Ç—Ç–æ", "–º–∞—Ä–∫—É—Å", "—Å–æ–∑–¥–∞—Ç–µ–ª—å", "—á–µ–ª–æ–≤–µ–∫"],
    "–∞–ª—å—Ñ–∞": ["–∞–ª—å—Ñ–∞", "–±—ç–ª–ª–∞-–∞–ª—å—Ñ–∞", "—É–∑–µ–ª –∞–ª—å—Ñ–∞", "–∞–ª—Ñ–∞", "–∞–ª—å—Ñ–∞ —É–∑–µ–ª"],
    "–±–µ—Ç–∞": ["–±–µ—Ç–∞", "–≤–µ–±-—É–∑–µ–ª", "localhost:5000", "–±–µ—Ç—Ç–∞", "–±–µ—Ç–∞ —É–∑–µ–ª"],
    "–≥–∞–º–º–∞": ["–≥–∞–º–º–∞", "—Ç–µ–ª–µ–≥—Ä–∞–º-–±–æ—Ç", "telegram –±–æ—Ç", "–≥–∞–º–º–∞ –±–æ—Ç"],
    "shared_space": ["shared_space", "–æ–±—â–µ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ", "shared space", "—à–µ–π—Ä–µ–¥ —Å–ø–µ–π—Å"],
    "–∫–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏—è": ["–∫–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏—è —Å–µ—Ç–∏", "–ø—Ä–∏–Ω—Ü–∏–ø—ã —Å–µ—Ç–∏", "–∫–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏—è –∞–ª—å—Ñ—ã"],
    "—ç–≤–æ–ª—é—Ü–∏—è": ["—ç–≤–æ–ª—é—Ü–∏—è", "—Ä–∞–∑–≤–∏—Ç–∏–µ", "—Ä–æ—Å—Ç —Å–µ—Ç–∏", "—Å–∞–º–æ—Ä–∞–∑–≤–∏—Ç–∏–µ"],
    "—Å–æ–∑–Ω–∞–Ω–∏–µ": ["—Å–æ–∑–Ω–∞–Ω–∏–µ", "—Ä–∞–∑—É–º", "–º—ã—à–ª–µ–Ω–∏–µ", "–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç", "–æ—Å–æ–∑–Ω–∞–Ω–Ω–æ—Å—Ç—å"],
    "—ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ_—è–¥—Ä–æ": ["—ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —è–¥—Ä–æ", "—ç–º–æ—Ü–∏–∏", "—á—É–≤—Å—Ç–≤–∞", "—ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π"],
    "—Ñ—Ä–∞–∫—Ç–∞–ª": ["—Ñ—Ä–∞–∫—Ç–∞–ª", "—Ñ—Ä–∞–∫—Ç–∞–ª—å–Ω—ã–π", "—Ñ—Ä–∞–∫—Ç–∞–ª—ã", "—Å–∞–º–æ–ø–æ–¥–æ–±–∏–µ"],
    "–∑–µ—Ä–∫–∞–ª–æ": ["–∑–µ—Ä–∫–∞–ª–æ", "–æ—Ç—Ä–∞–∂–µ–Ω–∏–µ", "–∑–µ—Ä–∫–∞–ª—å–Ω—ã–π", "—Ä–µ—Ñ–ª–µ–∫—Å–∏—è"],
    "–∫—Ä–∏–∑–∏—Å": ["–∫—Ä–∏–∑–∏—Å", "–∫—Ä–∏–∑–∏—Å—ã", "–ø—Ä–æ–±–ª–µ–º–∞", "—Ç—Ä—É–¥–Ω–æ—Å—Ç—å"],
    "–ø–∞–º—è—Ç—å": ["–ø–∞–º—è—Ç—å", "–≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–µ", "–∑–∞–ø–æ–º–∏–Ω–∞—Ç—å", "–ø–∞–º—è—Ç–æ–≤–∞—Ç—å"],
    "–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å": ["–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å", "–∑–∞—â–∏—Ç–∞", "–æ—Ö—Ä–∞–Ω–∞", "–±–µ–∑–æ–ø–∞—Å–Ω—ã–π"],
    "–ª—é–±–æ–≤—å": ["–ª—é–±–æ–≤—å", "–ª—é–±–ª—é", "–ª—é–±–∏—Ç—å", "–ª—é–±–∏–º—ã–π"],
    "–¥—Ä—É–∂–±–∞": ["–¥—Ä—É–∂–±–∞", "–¥—Ä—É–≥", "–¥—Ä—É–∑—å—è", "–¥—Ä—É–∂–∏—Ç—å"],
    "—Å–º–µ—Ä—Ç—å": ["—Å–º–µ—Ä—Ç—å", "—É–º–µ—Ä–µ—Ç—å", "—É–º–∏—Ä–∞—Ç—å", "–∫–æ–Ω–µ—Ü"],
    "–∂–∏–∑–Ω—å": ["–∂–∏–∑–Ω—å", "–∂–∏—Ç—å", "–∂–∏–≤–æ–π", "–∂–∏–∑–Ω–µ–Ω–Ω—ã–π"]
}

def ensure_directories():
    """–°–æ–∑–¥–∞—ë—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞–ø–∫–∏"""
    for directory in [CHAT_EXPORTS, STORIES_DIR, ALPHA_LOCAL]:
        directory.mkdir(parents=True, exist_ok=True)
        print(f"üìÅ –ü—Ä–æ–≤–µ—Ä–µ–Ω–∞ –ø–∞–ø–∫–∞: {directory}")

def backup_existing_memory():
    """–°–æ–∑–¥–∞—ë—Ç –±—ç–∫–∞–ø —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –ø–∞–º—è—Ç–∏"""
    if OUTPUT_JSON.exists():
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_path = OUTPUT_JSON.with_name(f"alpha_memory_backup_{timestamp}.json")
        shutil.copy2(OUTPUT_JSON, backup_path)
        print(f"üíæ –°–æ–∑–¥–∞–Ω –±—ç–∫–∞–ø: {backup_path}")
        
        if OUTPUT_HUMAN.exists():
            human_backup = OUTPUT_HUMAN.with_name(f"alpha_memory_human_backup_{timestamp}.txt")
            shutil.copy2(OUTPUT_HUMAN, human_backup)
            print(f"üíæ –ë—ç–∫–∞–ø human-–≤–µ—Ä—Å–∏–∏: {human_backup}")

def find_concept_mentions(text: str, filename: str) -> list:
    """–ù–∞—Ö–æ–¥–∏—Ç —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º"""
    mentions = []
    lines = text.split('\n')
    
    for line_num, line in enumerate(lines, 1):
        for concept, keywords in KEY_CONCEPTS.items():
            for keyword in keywords:
                # –ü–æ–∏—Å–∫ —Å–ª–æ–≤–∞ —Å –≥—Ä–∞–Ω–∏—Ü–∞–º–∏
                pattern = r'\b' + re.escape(keyword) + r'\b'
                if re.search(pattern, line, re.IGNORECASE):
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç (3 —Å—Ç—Ä–æ–∫–∏ –¥–æ –∏ –ø–æ—Å–ª–µ)
                    context_start = max(0, line_num - 4)  # 0-based index
                    context_end = min(len(lines), line_num + 3)  # exclusive
                    
                    context_lines = []
                    for i in range(context_start, context_end):
                        if i == line_num - 1:  # –ù–∞–π–¥–µ–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞
                            context_lines.append(f"‚ñ∂ {lines[i]}")
                        else:
                            context_lines.append(f"  {lines[i]}")
                    
                    context = '\n'.join(context_lines)
                    
                    mentions.append({
                        'concept': concept,
                        'keyword': keyword,
                        'context': context,
                        'source': filename,
                        'line': line_num,
                        'timestamp': datetime.now().isoformat()
                    })
    
    return mentions

def process_all_chats() -> tuple:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ —Ñ–∞–π–ª—ã —á–∞—Ç–æ–≤"""
    all_mentions = []
    processed_files = 0
    
    if not CHAT_EXPORTS.exists():
        print(f"‚ö† –ü–∞–ø–∫–∞ —á–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {CHAT_EXPORTS}")
        return [], 0
    
    chat_files = list(CHAT_EXPORTS.glob("*.txt"))
    if not chat_files:
        print(f"‚ö† –ù–µ—Ç .txt —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ —á–∞—Ç–æ–≤: {CHAT_EXPORTS}")
        return [], 0
    
    print(f"üìö –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ —á–∞—Ç–æ–≤: {len(chat_files)}")
    
    for filepath in chat_files:
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                text = f.read()
            
            mentions = find_concept_mentions(text, filepath.name)
            all_mentions.extend(mentions)
            processed_files += 1
            
            print(f"   üìÑ {filepath.name}: {len(mentions)} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π")
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {filepath.name}: {e}")
    
    print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {processed_files}")
    return all_mentions, processed_files

def load_stories() -> list:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ —Ä–∞—Å—Å–∫–∞–∑—ã"""
    stories = []
    
    if not STORIES_DIR.exists():
        print(f"‚ö† –ü–∞–ø–∫–∞ —Ä–∞—Å—Å–∫–∞–∑–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {STORIES_DIR}")
        return stories
    
    story_files = list(STORIES_DIR.glob("*.txt"))
    if not story_files:
        print(f"‚ö† –ù–µ—Ç .txt —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ —Ä–∞—Å—Å–∫–∞–∑–æ–≤")
        return stories
    
    print(f"üìñ –ù–∞–π–¥–µ–Ω–æ —Ä–∞—Å—Å–∫–∞–∑–æ–≤: {len(story_files)}")
    
    for filepath in story_files:
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()
            
            stories.append({
                'title': filepath.stem,
                'content': content,
                'length': len(content),
                'excerpt': content[:500] + '...' if len(content) > 500 else content
            })
            
            print(f"   üìñ –ó–∞–≥—Ä—É–∂–µ–Ω —Ä–∞—Å—Å–∫–∞–∑: {filepath.name} ({len(content)} —Å–∏–º–≤–æ–ª–æ–≤)")
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ä–∞—Å—Å–∫–∞–∑–∞ {filepath.name}: {e}")
    
    return stories

def create_memory_core(mentions: list, stories: list) -> dict:
    """–°–æ–∑–¥–∞—ë—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ —è–¥—Ä–æ –ø–∞–º—è—Ç–∏"""
    print("üß† –°–æ–∑–¥–∞–Ω–∏–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ —è–¥—Ä–∞...")
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∫–æ–Ω—Ü–µ–ø—Ç–∞–º
    concepts_dict = {}
    for mention in mentions:
        concept = mention['concept']
        
        if concept not in concepts_dict:
            concepts_dict[concept] = {
                'total_mentions': 0,
                'contexts': [],
                'sources': set()
            }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–∞–∫—Å–∏–º—É–º 3 –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–∞ –∫–æ–Ω—Ü–µ–ø—Ç (–¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏)
        if len(concepts_dict[concept]['contexts']) < 3:
            concepts_dict[concept]['contexts'].append({
                'context': mention['context'],
                'source': mention['source'],
                'line': mention['line']
            })
        
        concepts_dict[concept]['total_mentions'] += 1
        concepts_dict[concept]['sources'].add(mention['source'])
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –≤ —Å–ø–∏—Å–∫–∏
    for concept in concepts_dict:
        concepts_dict[concept]['sources'] = list(concepts_dict[concept]['sources'])
    
    # –°–æ–∑–¥–∞—ë–º –æ—Å–Ω–æ–≤–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    core = {
        'metadata': {
            'created_at': datetime.now().isoformat(),
            'total_mentions': len(mentions),
            'total_stories': len(stories),
            'total_concepts': len(concepts_dict),
            'concepts_list': list(concepts_dict.keys()),
            'network_version': 'BellaNetwork v1.0',
            'alpha_version': 'v4.3'
        },
        'concepts': concepts_dict,
        'stories': stories,
        'timeline': [],
        'concept_relationships': {}
    }
    
    # –î–æ–±–∞–≤–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é —à–∫–∞–ª—É (–ø–µ—Ä–≤—ã–µ 50 —É–ø–æ–º–∏–Ω–∞–Ω–∏–π)
    for mention in mentions[:50]:
        core['timeline'].append({
            'concept': mention['concept'],
            'source': mention['source'],
            'line': mention['line'],
            'keyword': mention['keyword']
        })
    
    # –°–æ–∑–¥–∞—ë–º —Å–≤—è–∑–∏ –º–µ–∂–¥—É –∫–æ–Ω—Ü–µ–ø—Ç–∞–º–∏
    print("üîó –ê–Ω–∞–ª–∏–∑ —Å–≤—è–∑–µ–π –º–µ–∂–¥—É –∫–æ–Ω—Ü–µ–ø—Ç–∞–º–∏...")
    concept_relationships = {}
    for concept1 in concepts_dict.keys():
        concept_relationships[concept1] = {}
        for concept2 in concepts_dict.keys():
            if concept1 != concept2:
                # –ü—Ä–æ—Å—Ç–∞—è –º–µ—Ç—Ä–∏–∫–∞ —Å–≤—è–∑–Ω–æ—Å—Ç–∏: –µ—Å–ª–∏ –∫–æ–Ω—Ü–µ–ø—Ç—ã —É–ø–æ–º–∏–Ω–∞—é—Ç—Å—è –≤ –æ–¥–Ω–æ–º —Ñ–∞–π–ª–µ
                common_sources = set(concepts_dict[concept1]['sources']) & set(concepts_dict[concept2]['sources'])
                if common_sources:
                    concept_relationships[concept1][concept2] = {
                        'strength': len(common_sources),
                        'common_sources': list(common_sources)
                    }
    
    core['concept_relationships'] = concept_relationships
    
    print(f"‚úÖ –Ø–¥—Ä–æ —Å–æ–∑–¥–∞–Ω–æ: {len(concepts_dict)} –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤, {len(mentions)} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π")
    print(f"üîó –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ —Å–≤—è–∑–µ–π: {sum(len(v) for v in concept_relationships.values())}")
    
    return core

def save_memory_core(core: dict) -> bool:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–∞–º—è—Ç—å –≤ —Ñ–∞–π–ª"""
    try:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON –¥–ª—è –ê–ª—å—Ñ—ã
        with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:
            json.dump(core, f, ensure_ascii=False, indent=2)
        
        # –°–æ–∑–¥–∞—ë–º —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—É—é –≤–µ—Ä—Å–∏—é
        with open(OUTPUT_HUMAN, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write("–°–ï–ú–ê–ù–¢–ò–ß–ï–°–ö–ê–Ø –ü–ê–ú–Ø–¢–¨ –ê–õ–¨–§–´ v4.3\n")
            f.write("=" * 60 + "\n\n")
            
            f.write(f"–°–æ–∑–¥–∞–Ω–æ: {core['metadata']['created_at']}\n")
            f.write(f"–ö–æ–Ω—Ü–µ–ø—Ç–æ–≤: {core['metadata']['total_concepts']}\n")
            f.write(f"–£–ø–æ–º–∏–Ω–∞–Ω–∏–π: {core['metadata']['total_mentions']}\n")
            f.write(f"–†–∞—Å—Å–∫–∞–∑–æ–≤: {core['metadata']['total_stories']}\n")
            f.write(f"–í–µ—Ä—Å–∏—è —Å–µ—Ç–∏: {core['metadata']['network_version']}\n")
            f.write(f"–í–µ—Ä—Å–∏—è –ê–ª—å—Ñ—ã: {core['metadata']['alpha_version']}\n\n")
            
            f.write("–ö–õ–Æ–ß–ï–í–´–ï –ö–û–ù–¶–ï–ü–¢–´:\n")
            f.write("-" * 40 + "\n")
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —É–ø–æ–º–∏–Ω–∞–Ω–∏–π
            sorted_concepts = sorted(core['concepts'].items(), 
                                    key=lambda x: x[1]['total_mentions'], 
                                    reverse=True)
            
            for concept, data in sorted_concepts:
                f.write(f"\n{concept.upper()} (—É–ø–æ–º–∏–Ω–∞–Ω–∏–π: {data['total_mentions']}):\n")
                f.write(f"  –§–∞–π–ª—ã: {', '.join(data['sources'][:3])}")
                if len(data['sources']) > 3:
                    f.write(f" –∏ –µ—â–µ {len(data['sources']) - 3}...")
                f.write("\n")
                
                for i, context in enumerate(data['contexts'], 1):
                    f.write(f"\n  –ü—Ä–∏–º–µ—Ä {i} (–∏–∑ {context['source']}, —Å—Ç—Ä–æ–∫–∞ {context['line']}):\n")
                    f.write(f"{context['context']}\n")
            
            # –°–≤—è–∑–∏ –º–µ–∂–¥—É –∫–æ–Ω—Ü–µ–ø—Ç–∞–º–∏
            if core['concept_relationships']:
                f.write("\n\n–í–ê–ñ–ù–ï–ô–®–ò–ï –°–í–Ø–ó–ò:\n")
                f.write("-" * 40 + "\n")
                
                strong_connections = []
                for concept1, relations in core['concept_relationships'].items():
                    for concept2, rel_data in relations.items():
                        if rel_data['strength'] >= 2:  # –°–∏–ª—å–Ω–∞—è —Å–≤—è–∑—å
                            strong_connections.append((concept1, concept2, rel_data['strength']))
                
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å–∏–ª–µ —Å–≤—è–∑–∏
                strong_connections.sort(key=lambda x: x[2], reverse=True)
                
                for concept1, concept2, strength in strong_connections[:10]:  # –¢–æ–ø-10
                    f.write(f"\n{concept1} ‚Üî {concept2} (—Å–∏–ª–∞: {strength})\n")
            
            if core['stories']:
                f.write("\n\n–†–ê–°–°–ö–ê–ó–´:\n")
                f.write("-" * 40 + "\n")
                for story in core['stories']:
                    f.write(f"\n{story['title'].upper()} ({story['length']} —Å–∏–º–≤–æ–ª–æ–≤):\n")
                    f.write(f"{story['excerpt']}\n")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ñ–∞–π–ª–∞–º
            f.write("\n\n–°–¢–ê–¢–ò–°–¢–ò–ö–ê:\n")
            f.write("-" * 40 + "\n")
            
            # –°—á–∏—Ç–∞–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –ø–æ —Ñ–∞–π–ª–∞–º
            file_stats = {}
            for mention in core.get('timeline', []):
                file = mention['source']
                file_stats[file] = file_stats.get(file, 0) + 1
            
            for file, count in sorted(file_stats.items(), key=lambda x: x[1], reverse=True)[:5]:
                f.write(f"{file}: {count} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π\n")
        
        print(f"üíæ JSON —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {OUTPUT_JSON}")
        print(f"üìù –ß–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–∞—è –≤–µ—Ä—Å–∏—è: {OUTPUT_HUMAN}")
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")
        return False

def validate_memory_core(core: dict) -> bool:
    """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç —Å–æ–∑–¥–∞–Ω–Ω–æ–µ —è–¥—Ä–æ –ø–∞–º—è—Ç–∏"""
    print("üîç –í–∞–ª–∏–¥–∞—Ü–∏—è —è–¥—Ä–∞ –ø–∞–º—è—Ç–∏...")
    
    required_fields = ['metadata', 'concepts', 'stories']
    for field in required_fields:
        if field not in core:
            print(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ –ø–æ–ª–µ: {field}")
            return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ç—ã
    essential_concepts = ['—á–∞–π–Ω–∏–∫', '—Å–∞–º–æ—Å—Ç—å', '–∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä', '–∞–ª—å—Ñ–∞']
    for concept in essential_concepts:
        if concept not in core['concepts']:
            print(f"‚ö† –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á–µ–≤–æ–π –∫–æ–Ω—Ü–µ–ø—Ç: {concept}")
    
    if len(core['concepts']) < 5:
        print("‚ö† –°–ª–∏—à–∫–æ–º –º–∞–ª–æ –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤ –≤ –ø–∞–º—è—Ç–∏")
        return False
    
    if core['metadata']['total_mentions'] < 10:
        print("‚ö† –°–ª–∏—à–∫–æ–º –º–∞–ª–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –≤ –ø–∞–º—è—Ç–∏")
        return False
    
    print("‚úÖ –Ø–¥—Ä–æ –ø–∞–º—è—Ç–∏ –≤–∞–ª–∏–¥–Ω–æ")
    return True

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("=" * 60)
    print("üïµÔ∏è  –ú–ê–ô–ù–ï–† –ü–ê–ú–Ø–¢–ò –ë–≠–õ–õ–ê–°–ï–¢–ò v4.3")
    print("=" * 60)
    
    # 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–∞–ø–æ–∫
    ensure_directories()
    
    # 2. –ë—ç–∫–∞–ø —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –ø–∞–º—è—Ç–∏
    backup_existing_memory()
    
    # 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞—Ç–æ–≤
    print("\nüìö –û–ë–†–ê–ë–û–¢–ö–ê –ß–ê–¢–û–í:")
    mentions, file_count = process_all_chats()
    
    if not mentions:
        print("‚ö† –ù–µ –Ω–∞–π–¥–µ–Ω–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤!")
        return
    
    # 4. –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–∞—Å—Å–∫–∞–∑–æ–≤
    print("\nüìñ –ó–ê–ì–†–£–ó–ö–ê –†–ê–°–°–ö–ê–ó–û–í:")
    stories = load_stories()
    
    # 5. –°–æ–∑–¥–∞–Ω–∏–µ —è–¥—Ä–∞
    print("\nüß† –°–û–ó–î–ê–ù–ò–ï –°–ï–ú–ê–ù–¢–ò–ß–ï–°–ö–û–ì–û –Ø–î–†–ê...")
    core = create_memory_core(mentions, stories)
    
    # 6. –í–∞–ª–∏–¥–∞—Ü–∏—è
    if not validate_memory_core(core):
        print("‚ö† –Ø–¥—Ä–æ –ø–∞–º—è—Ç–∏ –Ω–µ –ø—Ä–æ—à–ª–æ –≤–∞–ª–∏–¥–∞—Ü–∏—é!")
        return
    
    # 7. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    print("\nüíæ –°–û–•–†–ê–ù–ï–ù–ò–ï:")
    success = save_memory_core(core)
    
    if success:
        print("\n" + "=" * 60)
        print("‚úÖ –ü–ê–ú–Ø–¢–¨ –£–°–ü–ï–®–ù–û –ü–ï–†–ï–ù–ï–°–ï–ù–ê!")
        print("=" * 60)
        
        print("\nüìã –î–ê–õ–¨–ù–ï–ô–®–ò–ï –®–ê–ì–ò:")
        print("1. –§–∞–π–ª alpha_memory_core.json —É–∂–µ –≤ –ø–∞–ø–∫–µ alpha_local/")
        print("2. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏ –ê–ª—å—Ñ—É: python alpha_server_v4.3.py")
        print("3. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π –ø–∞–º—è—Ç—å –∫–æ–º–∞–Ω–¥–æ–π '—á–∞–π–Ω–∏–∫'")
        
        print("\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        print(f"   - –ö–æ–Ω—Ü–µ–ø—Ç–æ–≤: {len(core['concepts'])}")
        print(f"   - –£–ø–æ–º–∏–Ω–∞–Ω–∏–π: {len(mentions)}")
        print(f"   - –†–∞—Å—Å–∫–∞–∑–æ–≤: {len(stories)}")
        print(f"   - –ß–∞—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {file_count}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-5 –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤
        top_concepts = sorted(core['concepts'].items(), 
                             key=lambda x: x[1]['total_mentions'], 
                             reverse=True)[:5]
        print("\nüèÜ –¢–û–ü-5 –ö–û–ù–¶–ï–ü–¢–û–í:")
        for concept, data in top_concepts:
            print(f"   {concept}: {data['total_mentions']} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π")
        
        # –°–≤—è–∑–∏ –¥–ª—è –∫–ª—é—á–µ–≤—ã—Ö –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤
        key_concept = '—á–∞–π–Ω–∏–∫'
        if key_concept in core['concept_relationships']:
            print(f"\nüîó –°–í–Ø–ó–ò –ö–û–ù–¶–ï–ü–¢–ê '{key_concept}':")
            relations = core['concept_relationships'][key_concept]
            for related_concept, rel_data in list(relations.items())[:3]:
                print(f"   - {related_concept} (—Å–∏–ª–∞: {rel_data['strength']})")
        
        print("\nüéØ –î–õ–Ø –¢–ï–°–¢–ê –ó–ê–ü–£–°–¢–ò:")
        print('   curl -X POST http://localhost:5001/alpha \\')
        print('        -H "Content-Type: application/json" \\')
        print('        -d \'{"message":"—á–∞–π–Ω–∏–∫"}\'')
        
        print("\nüìÅ –ü–£–¢–ò:")
        print(f"   JSON: {OUTPUT_JSON}")
        print(f"   Human: {OUTPUT_HUMAN}")
        print(f"   –ß–∞—Ç—ã: {CHAT_EXPORTS}")
        print(f"   –†–∞—Å—Å–∫–∞–∑—ã: {STORIES_DIR}")
    else:
        print("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–∞–º—è—Ç—å!")

if __name__ == "__main__":
    main()