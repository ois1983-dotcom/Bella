"""
–ì–õ–ê–í–ù–´–ô –ú–ï–ù–ï–î–ñ–ï–† –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–ê–õ–¨–ù–û–ì–û –ö–û–î–ê v1.2
–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å–∞–º–æ–ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏—è —Å –£–ú–ù–´–ú –ê–ù–ê–õ–ò–ó–û–ú –∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–º –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º
–ü–û–õ–ù–ê–Ø –í–ï–†–°–ò–Ø —Å–æ –≤—Å–µ–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ –∏–∑ v1.1 –∏ –Ω–æ–≤—ã–º–∏ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–º–∏ —Ñ—É–Ω–∫—Ü–∏—è–º–∏ v1.2
"""

import ast
import json
import shutil
import hashlib
import time
import threading
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import fnmatch

class ExperimentalCodeManager:
    """
    –£–ú–ù–´–ô –ò –ë–ï–ó–û–ü–ê–°–ù–´–ô –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Å–∞–º–æ–ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏—è –∫–æ–¥–∞
    –†–∞–±–æ—Ç–∞–µ—Ç –¢–û–õ–¨–ö–û —Å experimental_*.py —Ñ–∞–π–ª–∞–º–∏
    –í–ï–†–°–ò–Ø 1.2: –£–ú–ù–´–ô –∞–Ω–∞–ª–∏–∑ —Å –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã, —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –í–°–ï –º–µ—Ç–æ–¥—ã v1.1
    """
    
    def __init__(self, security_core, alpha_local_path: Path):
        self.security = security_core
        self.alpha_local = alpha_local_path
        self.alpha_v5 = alpha_local_path.parent / "alpha_v5"
        
        # –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ –∫–æ–¥–∞
        self.experimental_dir = self.alpha_v5 / "experimental"
        self.experimental_dir.mkdir(parents=True, exist_ok=True)
        
        # –ù–ê–°–¢–†–û–ô–ö–ò –î–õ–Ø –ë–û–õ–¨–®–ò–• –§–ê–ô–õ–û–í (–ò–ó–ú–ï–ù–ï–ù–û)
        self.max_file_size_lines = 2000
        self.max_function_lines = 100
        self.max_nested_loops = 5
        
        # –£–ú–ù–´–ï –§–ò–õ–¨–¢–†–´ v1.2
        self.architectural_patterns = [
            "fallback",
            "backup",
            "reserve",
            "default",
            "emotional_gradients",
            "narrative_markers",
            "json.load",
            "except:"
        ]
        
        # –°–æ–∑–¥–∞—ë–º –±–∞–∑–æ–≤—ã–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
        self._create_base_experimental_file()
        
        # –ñ—É—Ä–Ω–∞–ª –∏–∑–º–µ–Ω–µ–Ω–∏–π
        self.change_log = self.alpha_local / "experimental_changes.json"
        self._init_change_log()
        
        # –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤
        self.file_locks = {}
        self.lock_timeout = 30
        
        # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤
        self.max_backups = 10
        self._clean_old_backups()
        
        print(f">> ExperimentalCodeManager v1.2 –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        print(f">> –†–∞–±–æ—á–∞—è –ø–∞–ø–∫–∞: {self.experimental_dir}")
        print(f">> –£–ú–ù–´–ô –∞–Ω–∞–ª–∏–∑: –í–ö–õ–Æ–ß–ï–ù (–ø–æ–Ω–∏–º–∞–µ—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É)")
    
    def _create_base_experimental_file(self):
        """–°–æ–∑–¥–∞—ë—Ç –±–∞–∑–æ–≤—ã–π experimental —Ñ–∞–π–ª –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç"""
        base_file = self.experimental_dir / "experimental_base.py"
        if not base_file.exists():
            base_content = '''
"""
–≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–ê–õ–¨–ù–´–ô –§–ê–ô–õ –î–õ–Ø –°–ê–ú–û–ü–ï–†–ï–ü–ò–°–´–í–ê–ù–ò–Ø v1.2
Alpha v5.4 –º–æ–∂–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ –∏–∑–º–µ–Ω—è—Ç—å —ç—Ç–æ—Ç —Ñ–∞–π–ª
"""

def experimental_function():
    """–ü—Ä–∏–º–µ—Ä —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ —É–ª—É—á—à–µ–Ω–∏—è"""
    return "–≠—Ç–æ experimental –∫–æ–¥, –∫–æ—Ç–æ—Ä—ã–π Alpha –º–æ–∂–µ—Ç –∏–∑–º–µ–Ω—è—Ç—å"

def get_experimental_status():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ –∫–æ–¥–∞"""
    return {
        "status": "active",
        "version": "1.2",
        "last_modified": "2025-01-09",
        "purpose": "–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Å–∞–º–æ–ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏–µ –∫–æ–¥–∞ Alpha"
    }

# Alpha –º–æ–∂–µ—Ç –¥–æ–±–∞–≤–ª—è—Ç—å —Å—é–¥–∞ –Ω–æ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∏ —É–ª—É—á—à–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ
'''
            with open(base_file, 'w', encoding='utf-8') as f:
                f.write(base_content)
            print(f">> –°–æ–∑–¥–∞–Ω –±–∞–∑–æ–≤—ã–π experimental —Ñ–∞–π–ª: {base_file.name}")
    
    def _init_change_log(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∂—É—Ä–Ω–∞–ª –∏–∑–º–µ–Ω–µ–Ω–∏–π"""
        if not self.change_log.exists():
            with open(self.change_log, 'w', encoding='utf-8') as f:
                json.dump({
                    "changes": [],
                    "metadata": {
                        "created": datetime.now().isoformat(),
                        "max_entries": 100,
                        "purpose": "–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π experimental –∫–æ–¥–∞",
                        "version": "1.2"
                    }
                }, f, indent=2)
    
    def _clean_old_backups(self):
        """–û—á–∏—â–∞–µ—Ç —Å—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N"""
        backup_dir = self.alpha_local / "code_backups"
        if not backup_dir.exists():
            backup_dir.mkdir(parents=True, exist_ok=True)
            return
        
        backups = list(backup_dir.glob("checkpoint_*"))
        backups.sort(key=lambda x: x.stat().st_mtime)
        
        if len(backups) > self.max_backups:
            for backup in backups[:-self.max_backups]:
                try:
                    if backup.is_dir():
                        shutil.rmtree(backup)
                    else:
                        backup.unlink()
                    print(f">> –£–¥–∞–ª—ë–Ω —Å—Ç–∞—Ä—ã–π –±—ç–∫–∞–ø: {backup.name}")
                except Exception as e:
                    print(f">> ‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –±—ç–∫–∞–ø {backup.name}: {e}")
    
    def _acquire_file_lock(self, filename: str) -> bool:
        """–ü–æ–ª—É—á–∞–µ—Ç –±–ª–æ–∫–∏—Ä–æ–≤–∫—É —Ñ–∞–π–ª–∞"""
        lock_file = self.experimental_dir / f".{filename}.lock"
        
        if lock_file.exists():
            lock_age = time.time() - lock_file.stat().st_mtime
            if lock_age > self.lock_timeout:
                lock_file.unlink(missing_ok=True)
            else:
                return False
        
        try:
            with open(lock_file, 'w') as f:
                f.write(str(datetime.now().isoformat()))
            self.file_locks[filename] = lock_file
            return True
        except Exception as e:
            print(f">> ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ —Ñ–∞–π–ª–∞ {filename}: {e}")
            return False
    
    def _release_file_lock(self, filename: str):
        """–û—Å–≤–æ–±–æ–∂–¥–∞–µ—Ç –±–ª–æ–∫–∏—Ä–æ–≤–∫—É —Ñ–∞–π–ª–∞"""
        if filename in self.file_locks:
            lock_file = self.file_locks[filename]
            try:
                lock_file.unlink(missing_ok=True)
            except:
                pass
            del self.file_locks[filename]
    
    def create_safe_checkpoint(self) -> Optional[str]:
        """–°–æ–∑–¥–∞—ë—Ç –±–µ–∑–æ–ø–∞—Å–Ω—ã–π checkpoint (—Ç–æ–ª—å–∫–æ experimental —Ñ–∞–π–ª—ã)"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            checkpoint_dir = self.alpha_local / "code_backups" / f"experimental_checkpoint_{timestamp}"
            checkpoint_dir.mkdir(parents=True, exist_ok=True)
            
            experimental_files = list(self.experimental_dir.glob("*.py"))
            
            for file in experimental_files:
                shutil.copy2(file, checkpoint_dir / file.name)
            
            metadata = {
                "timestamp": datetime.now().isoformat(),
                "type": "experimental_checkpoint",
                "files": [f.name for f in experimental_files],
                "total_size": sum(f.stat().st_size for f in experimental_files),
                "purpose": "–ê–≤—Ç–æ–Ω–æ–º–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –ø–µ—Ä–µ–¥ –∏–∑–º–µ–Ω–µ–Ω–∏–µ–º –∫–æ–¥–∞",
                "version": "1.2"
            }
            
            with open(checkpoint_dir / "metadata.json", 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2)
            
            print(f">> –°–æ–∑–¥–∞–Ω –±–µ–∑–æ–ø–∞—Å–Ω—ã–π checkpoint: {checkpoint_dir.name}")
            
            self._clean_old_backups()
            
            return checkpoint_dir.name
            
        except Exception as e:
            print(f">> –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è checkpoint: {e}")
            return None
    
    def analyze_experimental_code_safely(self) -> List[Dict]:
        """
        –£–ú–ù–´–ô –ê–ù–ê–õ–ò–ó –ö–û–î–ê v1.2
        –° –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–º –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π
        """
        suggestions = []
        
        for py_file in self.experimental_dir.glob("*.py"):
            if not self._acquire_file_lock(py_file.name):
                continue
            
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    code = f.read()
                
                # üî¥ v1.2: –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–º
                if self._is_architectural_file(py_file.name, code):
                    print(f">> üèõÔ∏è  –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π —Ñ–∞–π–ª: {py_file.name} - —Ç–æ–ª—å–∫–æ –±–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞")
                    
                    # –î–ª—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¢–û–õ–¨–ö–û –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞ –∏ –æ—á–µ–Ω—å –±–æ–ª—å—à–∏—Ö —Ä–∞–∑–º–µ—Ä–æ–≤
                    try:
                        ast.parse(code)
                    except SyntaxError as e:
                        suggestions.append({
                            "filename": py_file.name,
                            "issue_type": "syntax_error",
                            "description": f"–°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ–º —Ñ–∞–π–ª–µ: {e.msg}",
                            "priority": 10,
                            "line": e.lineno
                        })
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –û–ß–ï–ù–¨ –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ (—Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ)
                    lines = code.split('\n')
                    if len(lines) > 5000:  # –û—á–µ–Ω—å –±–æ–ª—å—à–æ–π –ª–∏–º–∏—Ç –¥–ª—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
                        suggestions.append({
                            "filename": py_file.name,
                            "issue_type": "file_too_large",
                            "description": f"–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π —Ñ–∞–π–ª –û–ß–ï–ù–¨ –±–æ–ª—å—à–æ–π ({len(lines)} —Å—Ç—Ä–æ–∫)",
                            "priority": 2,  # –ù–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
                            "suggestion": "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π —Ñ–∞–π–ª –æ—á–µ–Ω—å –±–æ–ª—å—à–æ–π, –Ω–æ —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–æ—Ä–º–∞–ª—å–Ω–æ"
                        })
                    
                    continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Å—Ç–∞–ª—å–Ω–æ–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
                
                # üî¥ v1.2: –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –ù–ï –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
                issues = self._analyze_with_intelligence(code, py_file.name)
                
                if issues:
                    for issue in issues:
                        if not self._is_false_positive_v2(issue, code, py_file.name):
                            suggestion = {
                                "filename": py_file.name,
                                "line": issue.get("line", 0),
                                "issue_type": issue["type"],
                                "description": issue["description"],
                                "priority": self._calculate_priority_v2(issue, py_file.name),
                                "code_snippet": issue.get("code_snippet", "")[:150]
                            }
                            suggestions.append(suggestion)
                
                # –ü–†–û–í–ï–†–ö–ê –†–ê–ó–ú–ï–†–ê –§–ê–ô–õ–ê (—Ç–æ–ª—å–∫–æ –¥–ª—è –Ω–µ-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã—Ö)
                metrics = self._calculate_code_metrics(code)
                
                if metrics["line_count"] > self.max_file_size_lines:
                    suggestions.append({
                        "filename": py_file.name,
                        "issue_type": "file_too_large",
                        "description": f"–§–∞–π–ª –æ—á–µ–Ω—å –±–æ–ª—å—à–æ–π ({metrics['line_count']} —Å—Ç—Ä–æ–∫)",
                        "priority": 3,
                        "suggestion": "–†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –º–æ–¥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏"
                    })
                
                if metrics["comment_ratio"] < 0.05:
                    suggestions.append({
                        "filename": py_file.name,
                        "issue_type": "low_comments",
                        "description": f"–ú–∞–ª–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ ({metrics['comment_ratio']:.1%})",
                        "priority": 4,
                        "suggestion": "–î–æ–±–∞–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é"
                    })
                    
            except Exception as e:
                print(f">> ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∞–π–ª–∞ {py_file.name}: {e}")
            finally:
                self._release_file_lock(py_file.name)
        
        suggestions.sort(key=lambda x: x["priority"], reverse=True)
        return suggestions[:7]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–æ–ª—å—à–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å v1.1
    
    def _is_architectural_file(self, filename: str, code: str) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–º (v1.2)"""
        lower_name = filename.lower()
        lower_code = code.lower()
        
        # –§–∞–π–ª—ã —Å —ç—Ç–∏–º–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏ –≤ –∏–º–µ–Ω–∏ - –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ
        architectural_names = ["integrator", "emotional", "core", "manager", "controller", "architectural"]
        if any(pattern in lower_name for pattern in architectural_names):
            return True
        
        # –§–∞–π–ª—ã —Å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–º–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏ –≤ –∫–æ–¥–µ
        for pattern in self.architectural_patterns:
            if pattern in lower_code:
                return True
        
        # –§–∞–π–ª—ã —Å JSON —Å—Ç—Ä—É–∫—Ç—É—Ä–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö
        if "json.dump" in code or "json.load" in code:
            # –ù–æ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –¥–∞–Ω–Ω—ã–µ, –∞ –Ω–µ –ø—Ä–æ—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
            if "except:" in code:
                return True
        
        # –§–∞–π–ª—ã —Å fallback-—Å—Ç—Ä—É–∫—Ç—É—Ä–∞–º–∏
        if "fallback" in lower_code or "backup" in lower_code or "default" in lower_code:
            return True
        
        return False
    
    def _analyze_with_intelligence(self, code: str, filename: str) -> List[Dict]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–¥ —Å –ø–æ–º–æ—â—å—é AST (—É–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è v1.2)"""
        issues = []
        
        try:
            tree = ast.parse(code)
            
            # –£–°–¢–ê–ù–û–í–õ–ï–ù–û –°–í–Ø–ó–´–í–ê–ù–ò–ï –†–û–î–ò–¢–ï–õ–ï–ô –î–õ–Ø –£–ó–õ–û–í
            for node in ast.walk(tree):
                for child in ast.iter_child_nodes(node):
                    child.parent = node
            
            for node in ast.walk(tree):
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≥–ª—É–±–æ–∫—É—é –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç—å —Ü–∏–∫–ª–æ–≤ (—É–≤–µ–ª–∏—á–µ–Ω –ª–∏–º–∏—Ç)
                if isinstance(node, (ast.For, ast.While)):
                    nested_count = self._count_nested_loops(node)
                    if nested_count >= self.max_nested_loops:
                        issues.append({
                            "type": "nested_loops",
                            "description": f"–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö —Ü–∏–∫–ª–æ–≤ ({nested_count} —É—Ä–æ–≤–Ω—è)",
                            "line": node.lineno if hasattr(node, 'lineno') else 0,
                            "code_snippet": ast.get_source_segment(code, node)[:200] if hasattr(node, 'lineno') else ""
                        })
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥–ª–∏–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ (—É–≤–µ–ª–∏—á–µ–Ω –ª–∏–º–∏—Ç)
                if isinstance(node, ast.FunctionDef):
                    function_length = len(node.body)
                    if function_length > self.max_function_lines:
                        issues.append({
                            "type": "long_function",
                            "description": f"–§—É–Ω–∫—Ü–∏—è —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–∞—è ({function_length} —Å—Ç—Ä–æ–∫)",
                            "line": node.lineno if hasattr(node, 'lineno') else 0,
                            "function_name": node.name
                        })
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–ª–æ–∂–Ω—ã–µ —É—Å–ª–æ–≤–∏—è
                if isinstance(node, ast.If):
                    condition_complexity = self._calculate_condition_complexity(node.test)
                    if condition_complexity >= 5:
                        issues.append({
                            "type": "complex_condition",
                            "description": f"–°–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω–æ–µ —É—Å–ª–æ–≤–∏–µ ({condition_complexity} –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤)",
                            "line": node.lineno if hasattr(node, 'lineno') else 0
                        })
            
        except SyntaxError as e:
            issues.append({
                "type": "syntax_error",
                "description": f"–°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e.msg}",
                "line": e.lineno if hasattr(e, 'lineno') else 0
            })
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞
        duplicate_issues = self._check_duplicate_code(code)
        issues.extend(duplicate_issues)
        
        return issues
    
    def _count_nested_loops(self, node) -> int:
        """–°—á–∏—Ç–∞–µ—Ç —É—Ä–æ–≤–µ–Ω—å –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏ —Ü–∏–∫–ª–æ–≤ (—Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ)"""
        count = 0
        for child in ast.iter_child_nodes(node):
            if isinstance(child, (ast.For, ast.While)):
                if hasattr(child, 'parent') and child.parent == node:
                    count = max(count, 1 + self._count_nested_loops(child))
        return count
    
    def _calculate_condition_complexity(self, node) -> int:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç—å —É—Å–ª–æ–≤–∏—è"""
        if isinstance(node, ast.BoolOp):
            return len(node.values)
        elif isinstance(node, ast.Compare):
            return 1 + len(node.ops)
        elif isinstance(node, ast.UnaryOp):
            return 1 + self._calculate_condition_complexity(node.operand)
        elif isinstance(node, (ast.BinOp, ast.Call, ast.Attribute)):
            return 1
        else:
            return 0
    
    def _check_duplicate_code(self, code: str) -> List[Dict]:
        """–û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞ –≤ —Ñ–∞–π–ª–µ (–ø–æ–ª–Ω–∞—è –≤–µ—Ä—Å–∏—è –∏–∑ v1.1)"""
        issues = []
        lines = code.split('\n')
        
        # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
        code_lines = []
        for i, line in enumerate(lines):
            stripped = line.strip()
            if stripped and not stripped.startswith('#') and not stripped.startswith('"""'):
                normalized = ' '.join(stripped.split())
                code_lines.append((i, normalized))
        
        # –ò—â–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–∑ 4+ —Å—Ç—Ä–æ–∫
        sequence_length = 4
        for i in range(len(code_lines) - sequence_length):
            seq_indices = [code_lines[j][0] for j in range(i, i + sequence_length)]
            seq_text = [code_lines[j][1] for j in range(i, i + sequence_length)]
            
            for j in range(i + sequence_length, len(code_lines) - sequence_length):
                match_seq = [code_lines[k][1] for k in range(j, j + sequence_length)]
                
                if seq_text == match_seq:
                    issues.append({
                        "type": "duplicate_code",
                        "description": f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞ ({sequence_length} –∏–¥–µ–Ω—Ç–∏—á–Ω—ã—Ö —Å—Ç—Ä–æ–∫)",
                        "line": seq_indices[0] + 1,
                        "code_snippet": '; '.join(seq_text)[:150],
                        "duplicate_at": code_lines[j][0] + 1
                    })
                    break
        
        return issues
    
    def _calculate_code_metrics(self, code: str) -> Dict:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –±–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–æ–¥–∞"""
        lines = code.split('\n')
        total_lines = len(lines)
        
        comment_lines = sum(1 for line in lines if line.strip().startswith('#'))
        empty_lines = sum(1 for line in lines if not line.strip())
        code_lines = total_lines - comment_lines - empty_lines
        
        return {
            "line_count": total_lines,
            "code_lines": code_lines,
            "comment_lines": comment_lines,
            "empty_lines": empty_lines,
            "comment_ratio": comment_lines / code_lines if code_lines > 0 else 0
        }
    
    def _calculate_priority_v2(self, issue: Dict, filename: str) -> int:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã (v1.2 —Å —É—á–µ—Ç–æ–º —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞)"""
        base_priority = {
            "syntax_error": 10,
            "nested_loops": 6,
            "long_function": 5,
            "complex_condition": 4,
            "file_too_large": 3,
            "low_comments": 3,
            "duplicate_code": 4
        }.get(issue["type"], 5)
        
        # üî¥ v1.2: –ü–æ–Ω–∏–∂–∞–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤
        lower_name = filename.lower()
        if "test" in lower_name:
            base_priority = max(1, base_priority - 2)
        
        return base_priority
    
    def _is_false_positive_v2(self, issue: Dict, code: str, filename: str) -> bool:
        """–§–∏–ª—å—Ç—Ä—É–µ—Ç –ª–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è (—É–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è v1.2)"""
        issue_type = issue["issue_type"]
        code_snippet = issue.get("code_snippet", "").lower()
        
        if issue_type == "duplicate_code":
            # –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ JSON —Å—Ç—Ä—É–∫—Ç—É—Ä–∞—Ö - —ç—Ç–æ –¥–∞–Ω–Ω—ã–µ, –Ω–µ –∫–æ–¥
            if any(pattern in code_snippet for pattern in ['emotional_gradients', 'narrative_markers']):
                return True
            
            # –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ try-except –±–ª–æ–∫–∞—Ö - —ç—Ç–æ –æ—Ç–∫–∞–∑–æ—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å
            if 'try:' in code_snippet and 'except:' in code_snippet:
                return True
        
        if issue_type == "nested_loops":
            # –í–ª–æ–∂–µ–Ω–Ω—ã–µ —Ü–∏–∫–ª—ã –≤ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö - –Ω–æ—Ä–º–∞–ª—å–Ω–æ
            if "for i in range" in code_snippet and "for j in range" in code_snippet:
                return True
        
        if issue_type == "complex_condition":
            # –°–ª–æ–∂–Ω—ã–µ —É—Å–ª–æ–≤–∏—è –≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ - –Ω–æ—Ä–º–∞–ª—å–Ω–æ
            if "is not none" in code_snippet or "isinstance" in code_snippet:
                return True
        
        if issue_type == "file_too_large":
            # –ë–æ–ª—å—à–∏–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ç–æ—Ä—ã - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ
            if "integrator" in filename.lower():
                return True
        
        return False
    
    def apply_safe_improvement(self, suggestion: Dict) -> Dict:
        """
        –ü–†–ò–ú–ï–ù–Ø–ï–¢ –£–ú–ù–û–ï –£–õ–£–ß–®–ï–ù–ò–ï v1.2
        –° –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–º –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º –∏ –±–µ–∑–æ–ø–∞—Å–Ω—ã–º–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è–º–∏
        """
        result = {
            "success": False,
            "filename": suggestion["filename"],
            "action": "code_improvement",
            "timestamp": datetime.now().isoformat(),
            "error": None,
            "backup_created": False,
            "changes_made": []
        }
        
        filename = suggestion["filename"]
        filepath = self.experimental_dir / filename
        
        if not filepath.exists():
            result["error"] = f"–§–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {filename}"
            return result
        
        if not self._acquire_file_lock(filename):
            result["error"] = "–§–∞–π–ª –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –¥—Ä—É–≥–∏–º –ø—Ä–æ—Ü–µ—Å—Å–æ–º"
            return result
        
        try:
            # üî¥ v1.2: –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–º
            with open(filepath, 'r', encoding='utf-8') as f:
                current_code = f.read()
            
            if self._is_architectural_file(filename, current_code):
                result["success"] = True
                result["changes_made"] = ["–§–∞–π–ª –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π - —É–ª—É—á—à–µ–Ω–∏—è –Ω–µ —Ç—Ä–µ–±—É—é—Ç—Å—è"]
                result["note"] = "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ —Ñ–∞–π–ª—ã –∑–∞—â–∏—â–µ–Ω—ã –æ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π v1.2"
                return result
            
            # –î–ª—è –ù–ï –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ —Å–æ–∑–¥–∞–µ–º checkpoint
            checkpoint_id = self.create_safe_checkpoint()
            if checkpoint_id:
                result["backup_created"] = True
                result["checkpoint_id"] = checkpoint_id
            
            new_code = current_code
            change_applied = False
            
            issue_type = suggestion["issue_type"]
            
            if issue_type == "low_comments":
                new_code = self._add_smart_comments(current_code)
                result["changes_made"].append("–î–æ–±–∞–≤–ª–µ–Ω—ã –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏")
                change_applied = True
            
            elif issue_type == "long_function" and "function_name" in suggestion:
                func_name = suggestion["function_name"]
                new_code = self._split_long_function_safe(current_code, func_name)
                result["changes_made"].append(f"–î–æ–±–∞–≤–ª–µ–Ω TODO –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ {func_name}")
                change_applied = True
            
            elif issue_type == "duplicate_code":
                new_code = self._remove_duplicate_code(current_code)
                result["changes_made"].append("–£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞")
                change_applied = True
            
            elif issue_type == "file_too_large":
                new_code = self._add_large_file_header(current_code, suggestion)
                result["changes_made"].append("–î–æ–±–∞–≤–ª–µ–Ω –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è –±–æ–ª—å—à–æ–≥–æ —Ñ–∞–π–ª–∞")
                change_applied = True
            
            # –ï—Å–ª–∏ –Ω–µ –±—ã–ª–æ —Ä–µ–∞–ª—å–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π
            if not change_applied or new_code == current_code:
                result["success"] = True
                result["changes_made"] = ["–ò–∑–º–µ–Ω–µ–Ω–∏—è –Ω–µ —Ç—Ä–µ–±—É—é—Ç—Å—è –∏–ª–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã"]
                return result
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–æ–≤–æ–≥–æ –∫–æ–¥–∞
            validation = self._validate_python_code(new_code)
            if not validation["valid"]:
                result["error"] = f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {validation['error']}"
                
                if checkpoint_id:
                    self._restore_from_checkpoint(checkpoint_id)
                
                return result
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(new_code)
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º
            test_result = self._test_experimental_code(filename)
            if not test_result["success"]:
                result["error"] = f"–¢–µ—Å—Ç –Ω–µ –ø—Ä–æ–π–¥–µ–Ω: {test_result['error']}"
                
                if checkpoint_id:
                    self._restore_from_checkpoint(checkpoint_id)
                
                return result
            
            result["success"] = True
            result["validation"] = validation
            result["test_result"] = test_result
            
            self._log_change(suggestion, result)
            
            return result
            
        except Exception as e:
            result["error"] = f"–ò—Å–∫–ª—é—á–µ–Ω–∏–µ: {str(e)}"
            return result
            
        finally:
            self._release_file_lock(filename)
    
    def _add_large_file_header(self, code: str, suggestion: Dict) -> str:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ (–ø–æ–ª–Ω–∞—è –≤–µ—Ä—Å–∏—è –∏–∑ v1.1)"""
        lines = code.split('\n')
        
        # –ò—â–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
        header_added = False
        for i, line in enumerate(lines[:5]):
            if line.strip().startswith("# –ë–û–õ–¨–®–û–ô –§–ê–ô–õ:"):
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
                lines[i] = f"# –ë–û–õ–¨–®–û–ô –§–ê–ô–õ: {suggestion['description']} - –û–±–Ω–æ–≤–ª–µ–Ω–æ {datetime.now().strftime('%Y-%m-%d %H:%M')}"
                header_added = True
                break
        
        if not header_added:
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –ø–æ—Å–ª–µ –ø–µ—Ä–≤—ã—Ö —Å—Ç—Ä–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
            insert_pos = 0
            for i, line in enumerate(lines):
                if not line.strip().startswith('"""') and not line.strip().startswith('#'):
                    insert_pos = i
                    break
            
            large_file_comment = f"""# –ë–û–õ–¨–®–û–ô –§–ê–ô–õ: {suggestion['description']}
# –°–∏—Å—Ç–µ–º–∞ —Å–∞–º–æ–ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏—è –æ–±–Ω–∞—Ä—É–∂–∏–ª–∞, —á—Ç–æ —ç—Ç–æ—Ç —Ñ–∞–π–ª –±–æ–ª—å—à–æ–π.
# –≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ç–æ—Ä–æ–≤ –∏ —Å–ª–æ–∂–Ω—ã—Ö –º–æ–¥—É–ª–µ–π.
# –ü–æ—Å–ª–µ–¥–Ω—è—è –ø—Ä–æ–≤–µ—Ä–∫–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
            lines.insert(insert_pos, large_file_comment)
        
        return '\n'.join(lines)
    
    def _add_smart_comments(self, code: str) -> str:
        """–î–æ–±–∞–≤–ª—è–µ—Ç —É–º–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ (–ø–æ–ª–Ω–∞—è –≤–µ—Ä—Å–∏—è –∏–∑ v1.1)"""
        lines = code.split('\n')
        
        for i, line in enumerate(lines):
            if line.strip().startswith('def ') and i + 1 < len(lines):
                next_line = lines[i + 1].strip()
                if not next_line.startswith('"""') and not next_line.startswith('#'):
                    func_name = line.split('def ')[1].split('(')[0]
                    comment = f'    """–§—É–Ω–∫—Ü–∏—è {func_name}"""'
                    lines.insert(i + 1, comment)
        
        return '\n'.join(lines)
    
    def _split_long_function_safe(self, code: str, func_name: str) -> str:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–ª–∏–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ (—Ç–æ–ª—å–∫–æ –¥–æ–±–∞–≤–ª—è–µ—Ç TODO)"""
        lines = code.split('\n')
        
        for i, line in enumerate(lines):
            if f'def {func_name}' in line:
                todo_comment = f'    # TODO v1.2: –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ –¥–ª–∏–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ {func_name}'
                
                if i + 1 < len(lines):
                    lines.insert(i + 1, todo_comment)
                break
        
        return '\n'.join(lines)
    
    def _remove_duplicate_code(self, code: str) -> str:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏—Ä—É—é—â–µ–≥–æ—Å—è –∫–æ–¥–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (–ø–æ–ª–Ω–∞—è –≤–µ—Ä—Å–∏—è –∏–∑ v1.1)"""
        lines = code.split('\n')
        result_lines = []
        
        # –°–ª–æ–≤–∞—Ä—å –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –±–ª–æ–∫–æ–≤ –∫–æ–¥–∞
        seen_blocks = {}
        current_block = []
        block_start = 0
        
        for i, line in enumerate(lines):
            stripped = line.strip()
            
            # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ —Å—Ç—Ä–æ–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
            is_comment = stripped.startswith('#') or stripped.startswith('"""') or stripped == '"""'
            
            if not stripped or is_comment:
                # –ï—Å–ª–∏ –Ω–∞–∫–æ–ø–∏–ª—Å—è –±–ª–æ–∫ –∫–æ–¥–∞ - —Å–æ—Ö—Ä–∞–Ω—è–µ–º
                if current_block:
                    block_key = '|'.join([l.strip() for l in current_block if l.strip()])
                    if block_key in seen_blocks and len(current_block) >= 3:
                        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –≤–º–µ—Å—Ç–æ –¥—É–±–ª–∏–∫–∞—Ç–∞
                        indent = len(lines[block_start]) - len(lines[block_start].lstrip())
                        result_lines.append(' ' * indent + "# –î–£–ë–õ–ò–ö–ê–¢ –£–î–ê–õ–ï–ù (—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π –∫–æ–¥)")
                    else:
                        result_lines.extend(current_block)
                        seen_blocks[block_key] = True
                    current_block = []
                
                result_lines.append(line)
                continue
            
            # –ù–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –∫–æ–¥–∞
            if not current_block:
                block_start = i
            
            current_block.append(line)
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –±–ª–æ–∫–∞
        if current_block:
            block_key = '|'.join([l.strip() for l in current_block if l.strip()])
            if block_key in seen_blocks and len(current_block) >= 3:
                indent = len(lines[block_start]) - len(lines[block_start].lstrip())
                result_lines.append(' ' * indent + "# –î–£–ë–õ–ò–ö–ê–¢ –£–î–ê–õ–ï–ù (—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π –∫–æ–¥)")
            else:
                result_lines.extend(current_block)
        
        return '\n'.join(result_lines)
    
    def _validate_python_code(self, code: str) -> Dict:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç Python –∫–æ–¥ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –æ—Ç—Å—Ç—É–ø–æ–≤ (–ø–æ–ª–Ω–∞—è –≤–µ—Ä—Å–∏—è –∏–∑ v1.1)"""
        try:
            # –ë–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞
            ast.parse(code)
            
            # ‚úÖ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Å—Ç—É–ø–æ–≤
            lines = code.split('\n')
            indent_stack = [0]  # —Å—Ç–µ–∫ –æ—Ç—Å—Ç—É–ø–æ–≤
            
            for i, line in enumerate(lines, 1):
                if line.strip():  # –ù–µ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
                    current_indent = len(line) - len(line.lstrip())
                    
                    if current_indent > indent_stack[-1]:
                        # –ù–æ–≤—ã–π –±–ª–æ–∫ - –¥–æ–±–∞–≤–ª—è–µ–º –æ—Ç—Å—Ç—É–ø
                        indent_stack.append(current_indent)
                    elif current_indent < indent_stack[-1]:
                        # –ö–æ–Ω–µ—Ü –±–ª–æ–∫–∞ - —É–±–∏—Ä–∞–µ–º –æ—Ç—Å—Ç—É–ø—ã
                        while indent_stack and current_indent < indent_stack[-1]:
                            indent_stack.pop()
                        
                        if current_indent != indent_stack[-1]:
                            return {
                                "valid": False, 
                                "error": f"–ù–µ–≤–µ—Ä–Ω—ã–π –æ—Ç—Å—Ç—É–ø –Ω–∞ —Å—Ç—Ä–æ–∫–µ {i}: –æ–∂–∏–¥–∞–ª–æ—Å—å {indent_stack[-1]}, –ø–æ–ª—É—á–∏–ª–∏ {current_indent}"
                            }
            
            return {"valid": True, "error": None}
            
        except SyntaxError as e:
            return {"valid": False, "error": f"–°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e.msg} –Ω–∞ —Å—Ç—Ä–æ–∫–µ {e.lineno}"}
        except Exception as e:
            return {"valid": False, "error": f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {str(e)}"}
    
    def _test_experimental_code(self, filename: str) -> Dict:
        """–ü—Ä–æ—Å—Ç–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ experimental –∫–æ–¥–∞ (–ø–æ–ª–Ω–∞—è –≤–µ—Ä—Å–∏—è –∏–∑ v1.1)"""
        try:
            import importlib.util
            import sys
            
            filepath = self.experimental_dir / filename
            spec = importlib.util.spec_from_file_location(
                f"experimental_{filename.replace('.py', '')}",
                filepath
            )
            
            if spec is None:
                return {"success": False, "error": "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—é"}
            
            module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(module)
            
            if hasattr(module, 'experimental_function'):
                try:
                    result = module.experimental_function()
                    if not isinstance(result, str):
                        return {"success": False, "error": "–§—É–Ω–∫—Ü–∏—è –≤–µ—Ä–Ω—É–ª–∞ –Ω–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø"}
                except:
                    return {"success": False, "error": "–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏"}
            
            return {"success": True, "error": None}
            
        except Exception as e:
            return {"success": False, "error": f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {str(e)}"}
    
    def _restore_from_checkpoint(self, checkpoint_id: str) -> bool:
        """–í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∏–∑ checkpoint (–ø–æ–ª–Ω–∞—è –≤–µ—Ä—Å–∏—è –∏–∑ v1.1)"""
        try:
            checkpoint_dir = self.alpha_local / "code_backups" / checkpoint_id
            if not checkpoint_dir.exists():
                return False
            
            for py_file in checkpoint_dir.glob("*.py"):
                if py_file.name != "metadata.json":
                    target_file = self.experimental_dir / py_file.name
                    shutil.copy2(py_file, target_file)
            
            print(f">> –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –∏–∑ checkpoint: {checkpoint_id}")
            return True
            
        except Exception as e:
            print(f">> –û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –∏–∑ checkpoint {checkpoint_id}: {e}")
            return False
    
    def _log_change(self, suggestion: Dict, result: Dict):
        """–õ–æ–≥–∏—Ä—É–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–µ (–ø–æ–ª–Ω–∞—è –≤–µ—Ä—Å–∏—è –∏–∑ v1.1)"""
        try:
            with open(self.change_log, 'r', encoding='utf-8') as f:
                log_data = json.load(f)
            
            log_entry = {
                "timestamp": datetime.now().isoformat(),
                "suggestion": suggestion,
                "result": result,
                "status": "success" if result["success"] else "failed",
                "version": "1.2"
            }
            
            log_data["changes"].append(log_entry)
            
            if len(log_data["changes"]) > 100:
                log_data["changes"] = log_data["changes"][-100:]
            
            with open(self.change_log, 'w', encoding='utf-8') as f:
                json.dump(log_data, f, indent=2)
                
        except Exception as e:
            print(f">> –û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
    
    def get_status(self) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å –º–µ–Ω–µ–¥–∂–µ—Ä–∞ v1.2 (–ø–æ–ª–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å—é)"""
        experimental_files = list(self.experimental_dir.glob("*.py"))
        
        return {
            "status": "active",
            "version": "1.2",
            "experimental_dir": str(self.experimental_dir),
            "experimental_files": [f.name for f in experimental_files],
            "file_count": len(experimental_files),
            "max_backups": self.max_backups,
            "lock_timeout": self.lock_timeout,
            "safety_level": "high",
            "max_file_size_lines": self.max_file_size_lines,
            "max_function_lines": self.max_function_lines,
            "max_nested_loops": self.max_nested_loops,
            "intelligence_level": "architectural_aware",
            "architectural_protection": [
                "–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ç–æ—Ä–æ–≤ –∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —è–¥–µ—Ä",
                "–ó–∞—â–∏—Ç–∞ fallback-—Å—Ç—Ä—É–∫—Ç—É—Ä",
                "–ü–æ–Ω–∏–º–∞–Ω–∏–µ JSON –¥–∞–Ω–Ω—ã—Ö –∫–∞–∫ –¥–∞–Ω–Ω—ã—Ö, –∞ –Ω–µ –∫–æ–¥–∞",
                "–ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è —Ä–µ–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º –Ω–∞–¥ —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–º–∏"
            ],
            "detection_capabilities": [
                "–°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏",
                f"–í–ª–æ–∂–µ–Ω–Ω—ã–µ —Ü–∏–∫–ª—ã (>{self.max_nested_loops} —É—Ä–æ–≤–Ω–µ–π)",
                f"–î–ª–∏–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ (>{self.max_function_lines} —Å—Ç—Ä–æ–∫)",
                f"–°–ª–æ–∂–Ω—ã–µ —É—Å–ª–æ–≤–∏—è (>4 –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤)",
                f"–î—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞ (4+ –∏–¥–µ–Ω—Ç–∏—á–Ω—ã—Ö —Å—Ç—Ä–æ–∫)",
                f"–§–∞–π–ª—ã >{self.max_file_size_lines} —Å—Ç—Ä–æ–∫",
                "–ù–∏–∑–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ (<5%)"
            ],
            "restrictions": [
                "–¢–æ–ª—å–∫–æ experimental_*.py —Ñ–∞–π–ª—ã",
                "AST-–∞–Ω–∞–ª–∏–∑ –≤–º–µ—Å—Ç–æ regex",
                "–ë–ª–æ–∫–∏—Ä–æ–≤–∫–∏ —Ñ–∞–π–ª–æ–≤",
                "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –±—ç–∫–∞–ø—ã",
                "–í–∞–ª–∏–¥–∞—Ü–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ",
                "–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π v1.2",
                "–ó–∞—â–∏—Ç–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"
            ]
        }
    
    # üî¥ –í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–ù–´–ï –ú–ï–¢–û–î–´ –î–õ–Ø –ü–û–õ–ù–û–ô –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò:
    
    def _calculate_priority(self, issue: Dict) -> int:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –∏–∑ v1.1 –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)"""
        priority_map = {
            "syntax_error": 10,
            "nested_loops": 6,
            "long_function": 5,
            "complex_condition": 4,
            "file_too_large": 3,
            "low_comments": 3,
            "duplicate_code": 4
        }
        
        return priority_map.get(issue["type"], 5)
    
    def _is_false_positive(self, suggestion: Dict) -> bool:
        """–§–∏–ª—å—Ç—Ä—É–µ—Ç –ª–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –∏–∑ v1.1 –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)"""
        issue_type = suggestion["issue_type"]
        code_snippet = suggestion.get("code_snippet", "").lower()
        filename = suggestion.get("filename", "").lower()
        
        # –§–∞–π–ª—ã —Å "integrator" –º–æ–≥—É—Ç –±—ã—Ç—å –±–æ–ª—å—à–∏–º–∏ - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ
        if "integrator" in filename and issue_type == "file_too_large":
            return True
        
        # –ë–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã experimental - —ç—Ç–æ –æ–∂–∏–¥–∞–µ–º–æ
        if "experimental" in filename and issue_type == "file_too_large":
            lines = suggestion.get("description", "")
            if "5000" not in lines:  # –ï—Å–ª–∏ –º–µ–Ω—å—à–µ 5000 —Å—Ç—Ä–æ–∫ - –Ω–æ—Ä–º–∞–ª—å–Ω–æ
                return True
        
        if issue_type == "nested_loops":
            if "for i in range" in code_snippet and "for j in range" in code_snippet:
                return True
        
        if issue_type == "complex_condition":
            if "is not none" in code_snippet or "isinstance" in code_snippet:
                return True
        
        if issue_type == "duplicate_code":
            if all(word in code_snippet.lower() for word in ['print', 'test', 'debug']):
                return True
        
        return False
    
    def _split_long_function(self, code: str, func_name: str) -> str:
        """–†–∞–∑–¥–µ–ª—è–µ—Ç –¥–ª–∏–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –Ω–∞ —á–∞—Å—Ç–∏ (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –∏–∑ v1.1 –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)"""
        lines = code.split('\n')
        
        for i, line in enumerate(lines):
            if f'def {func_name}' in line:
                todo_comment = f'    # TODO: –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ –¥–ª–∏–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏'
                if i + 1 < len(lines):
                    lines.insert(i + 1, todo_comment)
                break
        
        return '\n'.join(lines)
    
    def _analyze_with_ast(self, code: str, filename: str) -> List[Dict]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–¥ —Å –ø–æ–º–æ—â—å—é AST (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –∏–∑ v1.1 –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)"""
        issues = []
        
        try:
            tree = ast.parse(code)
            
            # –£–°–¢–ê–ù–û–í–õ–ï–ù–û –°–í–Ø–ó–´–í–ê–ù–ò–ï –†–û–î–ò–¢–ï–õ–ï–ô –î–õ–Ø –£–ó–õ–û–í
            for node in ast.walk(tree):
                for child in ast.iter_child_nodes(node):
                    child.parent = node
            
            for node in ast.walk(tree):
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≥–ª—É–±–æ–∫—É—é –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç—å —Ü–∏–∫–ª–æ–≤ (—É–≤–µ–ª–∏—á–µ–Ω –ª–∏–º–∏—Ç)
                if isinstance(node, (ast.For, ast.While)):
                    nested_count = self._count_nested_loops(node)
                    if nested_count >= self.max_nested_loops:
                        issues.append({
                            "type": "nested_loops",
                            "description": f"–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö —Ü–∏–∫–ª–æ–≤ ({nested_count} —É—Ä–æ–≤–Ω—è)",
                            "line": node.lineno if hasattr(node, 'lineno') else 0,
                            "code_snippet": ast.get_source_segment(code, node)[:200] if hasattr(node, 'lineno') else ""
                        })
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥–ª–∏–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ (—É–≤–µ–ª–∏—á–µ–Ω –ª–∏–º–∏—Ç)
                if isinstance(node, ast.FunctionDef):
                    function_length = len(node.body)
                    if function_length > self.max_function_lines:
                        issues.append({
                            "type": "long_function",
                            "description": f"–§—É–Ω–∫—Ü–∏—è —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–∞—è ({function_length} —Å—Ç—Ä–æ–∫)",
                            "line": node.lineno if hasattr(node, 'lineno') else 0,
                            "function_name": node.name
                        })
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–ª–æ–∂–Ω—ã–µ —É—Å–ª–æ–≤–∏—è
                if isinstance(node, ast.If):
                    condition_complexity = self._calculate_condition_complexity(node.test)
                    if condition_complexity >= 5:  # –£–≤–µ–ª–∏—á–µ–Ω –ª–∏–º–∏—Ç
                        issues.append({
                            "type": "complex_condition",
                            "description": f"–°–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω–æ–µ —É—Å–ª–æ–≤–∏–µ ({condition_complexity} –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤)",
                            "line": node.lineno if hasattr(node, 'lineno') else 0
                        })
            
        except SyntaxError as e:
            issues.append({
                "type": "syntax_error",
                "description": f"–°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e.msg}",
                "line": e.lineno if hasattr(e, 'lineno') else 0
            })
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞
        duplicate_issues = self._check_duplicate_code(code)
        issues.extend(duplicate_issues)
        
        return issues

# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
if __name__ == "__main__":
    print("üß™ –ü–û–õ–ù–´–ô —Ç–µ—Å—Ç ExperimentalCodeManager v1.2...")
    
    class MockSecurity:
        def validate_action(self, *args, **kwargs):
            return True, "–†–∞–∑—Ä–µ—à–µ–Ω–æ", {}
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—É—â–∏–π –∫–∞—Ç–∞–ª–æ–≥ –¥–ª—è —Ç–µ—Å—Ç–∞
    from pathlib import Path
    test_dir = Path("test_experimental_v1_2")
    test_dir.mkdir(exist_ok=True)
    
    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫–∞—Ç–∞–ª–æ–≥–æ–≤
    test_experimental = test_dir / "experimental"
    test_experimental.mkdir(exist_ok=True)
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã
    test_file = test_experimental / "test_experimental.py"
    test_file.write_text('''
def test_function():
    """–¢–µ—Å—Ç–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    return "–¢–µ—Å—Ç"
''')
    
    # –°–æ–∑–¥–∞–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è —Ç–µ—Å—Ç–∞
    architectural_file = test_experimental / "test_integrator.py"
    architectural_file.write_text('''
# –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π —Ñ–∞–π–ª —Å JSON —Å—Ç—Ä—É–∫—Ç—É—Ä–∞–º–∏
import json

try:
    with open("test.json", "r") as f:
        data = json.load(f)
except:
    data = {"fallback": "–¥–∞–Ω–Ω—ã–µ", "emotional_gradients": {"fear": "—Å—Ç—Ä–∞—Ö"}}
''')
    
    manager = ExperimentalCodeManager(MockSecurity(), test_dir)
    
    print("\n1. –¢–µ—Å—Ç–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–æ–≤...")
    suggestions = manager.analyze_experimental_code_safely()
    print(f">> –ù–∞–π–¥–µ–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {len(suggestions)}")
    for i, s in enumerate(suggestions):
        print(f">>  {i+1}. {s['filename']}: {s['description'][:50]}...")
    
    print("\n2. –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å—Ç–∞—Ç—É—Å –º–µ–Ω–µ–¥–∂–µ—Ä–∞...")
    status = manager.get_status()
    print(f">> –í–µ—Ä—Å–∏—è: {status['version']}")
    print(f">> –§–∞–π–ª–æ–≤: {status['file_count']}")
    print(f">> –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–∞—è –∑–∞—â–∏—Ç–∞: {'–î–∞' if 'architectural_protection' in status else '–ù–µ—Ç'}")
    
    print("\n3. –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –º–µ—Ç–æ–¥–æ–≤ v1.1...")
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã
    test_code = "def test():\n    pass\n\n# –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ\nprint('test')\nprint('test')"
    issues = manager._analyze_with_ast(test_code, "test.py")
    print(f">> _analyze_with_ast –Ω–∞–π–¥–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º: {len(issues)}")
    
    priority = manager._calculate_priority({"type": "syntax_error"})
    print(f">> _calculate_priority –¥–ª—è syntax_error: {priority}")
    
    print("\n‚úÖ –ü–û–õ–ù–´–ô —Ç–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω")
    print("üìã –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
    print("   ‚Ä¢ –í—Å–µ –º–µ—Ç–æ–¥—ã v1.1 —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –∏ —Ä–∞–±–æ—Ç–∞—é—Ç")
    print("   ‚Ä¢ –ù–æ–≤—ã–µ –º–µ—Ç–æ–¥—ã v1.2 –¥–æ–±–∞–≤–ª–µ–Ω—ã –∏ —Ä–∞–±–æ—Ç–∞—é—Ç")
    print("   ‚Ä¢ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–∞—è –∑–∞—â–∏—Ç–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç")
    print("   ‚Ä¢ –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –æ–±–µ—Å–ø–µ—á–µ–Ω–∞")
    
    import shutil
    shutil.rmtree(test_dir, ignore_errors=True)
    
    print("‚úÖ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à—ë–Ω")