"""
–ò–ù–¢–ï–†–ù–ï–¢-–ò–°–°–õ–ï–î–û–í–ê–ù–ò–Ø –î–õ–Ø –ë–≠–õ–õ–´ (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π –¥–æ—Å—Ç—É–ø)
"""

import requests
from bs4 import BeautifulSoup
import json
from typing import Optional, List
import re

class InternetResearch:
    """–ü—Ä–æ—Å—Ç–æ–π –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–ø–æ–∏—Å–∫ –¥–ª—è –ë—ç–ª–ª—ã"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
    
    def simple_search(self, query: str, max_results: int = 3) -> List[dict]:
        """–ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ DuckDuckGo HTML"""
        try:
            url = f"https://duckduckgo.com/html/?q={query}"
            response = self.session.get(url, timeout=10)
            
            if response.status_code != 200:
                return []
            
            soup = BeautifulSoup(response.text, 'html.parser')
            results = []
            
            # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            for result in soup.find_all('a', class_='result__url', limit=max_results):
                title = result.get_text(strip=True)
                link = result.get('href')
                
                if title and link and 'http' in link:
                    # –ü–æ–ª—É—á–∞–µ–º –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
                    desc_elem = result.find_next('a', class_='result__snippet')
                    description = desc_elem.get_text(strip=True) if desc_elem else ""
                    
                    results.append({
                        'title': title,
                        'url': link,
                        'description': description[:200]
                    })
            
            return results
            
        except Exception as e:
            print(f">> –ò–Ω—Ç–µ—Ä–Ω–µ—Ç –ø–æ–∏—Å–∫ –æ—à–∏–±–∫–∞: {e}")
            return []
    
    def get_wikipedia_summary(self, topic: str) -> Optional[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑ Wikipedia"""
        try:
            url = f"https://ru.wikipedia.org/api/rest_v1/page/summary/{topic}"
            response = self.session.get(url, timeout=5)
            
            if response.status_code == 200:
                data = response.json()
                return data.get('extract', '')[:500]
        
        except:
            pass
        
        return None
    
    def research_topic(self, topic: str) -> dict:
        """–ò—Å—Å–ª–µ–¥—É–µ—Ç —Ç–µ–º—É –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ"""
        print(f">> üîç –ò—Å—Å–ª–µ–¥—É—é —Ç–µ–º—É: {topic}")
        
        research = {
            'topic': topic,
            'wikipedia_summary': None,
            'search_results': [],
            'key_points': []
        }
        
        # 1. Wikipedia
        research['wikipedia_summary'] = self.get_wikipedia_summary(topic)
        
        # 2. –ü–æ–∏—Å–∫
        research['search_results'] = self.simple_search(topic, max_results=5)
        
        # 3. –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã
        all_text = ""
        if research['wikipedia_summary']:
            all_text += research['wikipedia_summary'] + " "
        
        for result in research['search_results']:
            all_text += result.get('description', '') + " "
        
        # –ü—Ä–æ—Å—Ç–∞—è —ç–∫—Å—Ç—Ä–∞–∫—Ü–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        words = re.findall(r'\b[–∞-—è–ê-–Øa-zA-Z]{4,}\b', all_text.lower())
        from collections import Counter
        common_words = Counter(words).most_common(10)
        
        research['key_points'] = [word for word, count in common_words 
                                 if word not in ['—ç—Ç–æ', '—á—Ç–æ', '–∫–∞–∫', '–¥–ª—è', '–æ—á–µ–Ω—å']]
        
        return research

# –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ consciousness_core_v5_3.py
def add_internet_to_consciousness():
    """–î–æ–±–∞–≤–ª—è–µ—Ç –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–æ–¥—É–ª—å –≤ —Å–æ–∑–Ω–∞–Ω–∏–µ"""
    # –í __init__ DynamicConsciousness:
    print(">> üåê –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Internet Research...")
    try:
        from internet_research import InternetResearch
        self.internet_research = InternetResearch()
        print(">> ‚úÖ Internet Research –∑–∞–≥—Ä—É–∂–µ–Ω")
    except Exception as e:
        print(f">> ‚ö†Ô∏è Internet Research –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª—Å—è: {e}")
        self.internet_research = None