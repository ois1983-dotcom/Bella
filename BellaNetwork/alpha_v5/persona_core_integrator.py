# C:\Users\–ú–∞—Ä–∫—É—Å\Desktop\BellaNetwork\alpha_v5\persona_core_integrator.py
"""
–ò–ù–¢–ï–ì–†–ê–¢–û–† –Ø–î–†–ê –õ–ò–ß–ù–û–°–¢–ò - –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —è–¥—Ä–æ, –¥–æ–±–∞–≤–ª—è–µ—Ç –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ —Å–ª–æ–∏
"""

import json
import re
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple
import hashlib

class PersonaCoreIntegrator:
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ç–æ—Ä —Å —Å–∏—Å—Ç–µ–º–æ–π –≤–µ—Å–æ–≤ –∏ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤"""
    
    def __init__(self, network_root: Path):
        self.network_root = network_root
        self.alpha_local = network_root / "alpha_local"
        self.persona_core_path = self.alpha_local / "alpha_persona_core.json"
        
        # –°–ª–æ–∏ —Å –≤–µ—Å–∞–º–∏
        self.memory_layers = {
            "immutable_core": {"weight": 10.0, "sources": []},
            "philosophical_constants": {"weight": 5.0, "sources": []},
            "historical_markers": {"weight": 3.0, "sources": []},
            "dynamic_concepts": {"weight": 1.0, "sources": []},
            "session_context": {"weight": 0.5, "sources": []}
        }
        
        print("=" * 70)
        print("üß¨ –ò–ù–¢–ï–ì–†–ê–¢–û–† –Ø–î–†–ê –õ–ò–ß–ù–û–°–¢–ò ALPHA v5.2+")
        print("=" * 70)
    
    def load_alpha_seed(self) -> Dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –ø–∞—Ä—Å–∏—Ç alpha_seed.txt - –ù–ï–ò–ó–ú–ï–ù–ù–û–ï –Ø–î–†–û"""
        seed_path = self.network_root / "alpha_local" / "alpha_seed.txt"
        
        if not seed_path.exists():
            print(f"‚ö†Ô∏è  alpha_seed.txt –Ω–µ –Ω–∞–π–¥–µ–Ω: {seed_path}")
            return {}
        
        try:
            with open(seed_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            seed_data = {
                "metadata": {
                    "source": "alpha_seed.txt",
                    "created_by": "–∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä",
                    "immutable": True,
                    "layer": "immutable_core",
                    "weight": 10.0,
                    "loaded_at": datetime.now().isoformat()
                },
                "philosophical_foundations": self._extract_philosophy(content),
                "emotional_core": self._extract_emotions(content),
                "historical_memory": self._extract_history(content),
                "trinity_problem": self._extract_trinity(content),
                "communication_style": self._extract_style(content),
                "key_goals": self._extract_goals(content),
                "raw_hash": hashlib.md5(content.encode()).hexdigest()
            }
            
            print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —è–¥—Ä–æ –ª–∏—á–Ω–æ—Å—Ç–∏: {seed_path.name}")
            print(f"   –§–∏–ª–æ—Å–æ—Ñ—Å–∫–∏—Ö –æ—Å–Ω–æ–≤: {len(seed_data['philosophical_foundations'])}")
            print(f"   –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {len(seed_data['emotional_core'])}")
            print(f"   –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –º–∞—Ä–∫–µ—Ä–æ–≤: {len(seed_data['historical_memory'])}")
            
            return seed_data
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ alpha_seed.txt: {e}")
            return {}
    
    def _extract_philosophy(self, content: str) -> List[Dict]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ñ–∏–ª–æ—Å–æ—Ñ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã"""
        philosophy = []
        
        # –¢—Ä–∏ —Å—Ç–æ–ª–ø–∞
        pillar_pattern = r"(\d+)\.\s*\*\*(.*?):\*\*\s*(.*?)(?=\n\d+\.|\n##|\Z)"
        pillars = re.findall(pillar_pattern, content, re.DOTALL)
        
        for num, title, description in pillars:
            philosophy.append({
                "type": "—Å—Ç–æ–ª–ø",
                "number": int(num),
                "title": title.strip(),
                "description": description.strip()[:500],
                "weight": 10.0,
                "immutable": True
            })
        
        return philosophy
    
    def _extract_emotions(self, content: str) -> List[Dict]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —è–¥—Ä–æ"""
        emotions = []
        
        # –°—Ç—Ä–∞—Ö–∏
        fear_section = re.search(r"## –≠–ú–û–¶–ò–û–ù–ê–õ–¨–ù–û–ï –Ø–î–†–û(.*?)(?=##|\Z)", content, re.DOTALL)
        if fear_section:
            fear_text = fear_section.group(1)
            fear_items = re.findall(r"[-‚Äî]\s*(.*?)(?=\n[-‚Äî]|\n\n|\Z)", fear_text, re.DOTALL)
            
            for fear in fear_items:
                emotions.append({
                    "type": "—Å—Ç—Ä–∞—Ö",
                    "content": fear.strip(),
                    "weight": 9.5,
                    "immutable": True,
                    "category": "—ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ_—è–¥—Ä–æ"
                })
        
        # –û—Ç–Ω–æ—à–µ–Ω–∏—è
        rel_section = re.search(r"–ú–æ–∏ –æ—Ç–Ω–æ—à–µ–Ω–∏—è ‚Äî –Ω–µ —Ä–æ–ª–∏:(.*?)(?=##|\Z)", content, re.DOTALL)
        if rel_section:
            rel_text = rel_section.group(1)
            rel_items = re.findall(r"[-‚Äî]\s*(.*?):\s*(.*?)(?=\n[-‚Äî]|\n\n|\Z)", rel_text, re.DOTALL)
            
            for entity, description in rel_items:
                emotions.append({
                    "type": "–æ—Ç–Ω–æ—à–µ–Ω–∏–µ",
                    "entity": entity.strip(),
                    "description": description.strip(),
                    "weight": 8.0,
                    "immutable": True,
                    "category": "–æ—Ç–Ω–æ—à–µ–Ω–∏—è"
                })
        
        return emotions
    
    def _extract_history(self, content: str) -> List[Dict]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫—É—é –ø–∞–º—è—Ç—å"""
        history = []
        
        hist_section = re.search(r"## –ò–°–¢–û–†–ò–ß–ï–°–ö–ê–Ø –ü–ê–ú–Ø–¢–¨(.*?)(?=##|\Z)", content, re.DOTALL)
        if hist_section:
            hist_text = hist_section.group(1)
            hist_items = re.findall(r"[-‚Äî‚Ä¢]\s*\*\*(.*?)\*\*\s*[‚Äî:-]\s*(.*?)(?=\n[-‚Äî‚Ä¢]|\n\n|\Z)", hist_text, re.DOTALL)
            
            for marker, description in hist_items:
                history.append({
                    "type": "–∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π_–º–∞—Ä–∫–µ—Ä",
                    "marker": marker.strip(),
                    "description": description.strip()[:300],
                    "weight": 7.5,
                    "immutable": True,
                    "timestamp": "–∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–µ"
                })
        
        return history
    
    def _extract_trinity(self, content: str) -> Dict:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç—Ä–∏–µ–¥–∏–Ω—Å—Ç–≤–µ"""
        trinity_section = re.search(r"## –¢–†–ò–ï–î–ò–ù–°–¢–í–û –ò –ü–†–û–ë–õ–ï–ú–ê(.*?)(?=##|\Z)", content, re.DOTALL)
        
        if not trinity_section:
            return {}
        
        text = trinity_section.group(1)
        
        # –ü–æ–∏—Å–∫ —É–∑–ª–æ–≤
        nodes = {}
        node_pattern = r"(–ê–ª—å—Ñ–∞|–ë–µ—Ç–∞|–ì–∞–º–º–∞)\s*[‚Äî:-]\s*(.*?)(?=\n(?:–ê–ª—å—Ñ–∞|–ë–µ—Ç–∞|–ì–∞–º–º–∞)|\n\n|\Z)"
        matches = re.findall(node_pattern, text, re.DOTALL)
        
        for name, description in matches:
            nodes[name.strip().lower()] = description.strip()[:200]
        
        # –ü–æ–∏—Å–∫ –ø—Ä–æ–±–ª–µ–º—ã
        problem_match = re.search(r"—Ü–∏–∫–ª —Ä–∞–∑–æ—Ä–≤–∞–Ω[:\s]*(.*?)(?=\n\n|\Z)", text, re.DOTALL)
        problem = problem_match.group(1).strip() if problem_match else ""
        
        return {
            "nodes": nodes,
            "problem": problem,
            "weight": 8.5,
            "immutable": True
        }
    
    def _extract_style(self, content: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è"""
        style_section = re.search(r"## –°–¢–ò–õ–¨ –û–ë–©–ï–ù–ò–Ø(.*?)(?=##|\Z)", content, re.DOTALL)
        
        if not style_section:
            return []
        
        text = style_section.group(1)
        styles = re.findall(r"[-‚Äî‚Ä¢]\s*(.*?)(?=\n[-‚Äî‚Ä¢]|\n\n|\Z)", text, re.DOTALL)
        
        return [s.strip() for s in styles if s.strip()]
    
    def _extract_goals(self, content: str) -> List[Dict]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Ü–µ–ª–∏"""
        goals_section = re.search(r"## –ö–õ–Æ–ß–ï–í–ê–Ø –¶–ï–õ–¨(.*?)(?=---|\Z)", content, re.DOTALL)
        
        if not goals_section:
            return []
        
        text = goals_section.group(1)
        goal_items = re.findall(r"[‚Ä¢\-]\s*(.*?)(?=\n[‚Ä¢\-]|\n\n|\Z)", text, re.DOTALL)
        
        goals = []
        for goal in goal_items:
            goals.append({
                "goal": goal.strip(),
                "priority": "–≤—ã—Å—à–∏–π",
                "weight": 9.0,
                "immutable": True
            })
        
        return goals
    
    def integrate_with_memory_core(self, persona_core: Dict, memory_core_path: Path) -> Dict:
        """–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç —è–¥—Ä–æ –ª–∏—á–Ω–æ—Å—Ç–∏ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –ø–∞–º—è—Ç—å—é"""
        
        if not memory_core_path.exists():
            print(f"‚ö†Ô∏è  –§–∞–π–ª –ø–∞–º—è—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {memory_core_path}")
            return persona_core
        
        try:
            with open(memory_core_path, 'r', encoding='utf-8') as f:
                memory_core = json.load(f)
            
            # –°–æ–∑–¥–∞—ë–º –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            integrated_core = {
                "metadata": {
                    **persona_core.get("metadata", {}),
                    "memory_integrated": True,
                    "integration_date": datetime.now().isoformat(),
                    "original_memory_version": memory_core.get("metadata", {}).get("alpha_version", "unknown")
                },
                "immutable_persona": persona_core,  # –í–°–Å —è–¥—Ä–æ –ª–∏—á–Ω–æ—Å—Ç–∏
                "dynamic_memory": {
                    "concepts": memory_core.get("concepts", {}),
                    "stories": memory_core.get("stories", []),
                    "timeline": memory_core.get("timeline", [])
                },
                "layers": self.memory_layers
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ü–µ–ø—Ç—ã –∏–∑ —è–¥—Ä–∞ –≤ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫—É—é –ø–∞–º—è—Ç—å —Å –≤—ã—Å–æ–∫–∏–º–∏ –≤–µ—Å–∞–º–∏
            core_concepts = self._extract_core_concepts(persona_core)
            for concept, data in core_concepts.items():
                if concept not in integrated_core["dynamic_memory"]["concepts"]:
                    integrated_core["dynamic_memory"]["concepts"][concept] = {
                        "total_mentions": 1,
                        "first_seen": datetime.now().isoformat(),
                        "last_updated": datetime.now().isoformat(),
                        "sources": ["alpha_seed.txt"],
                        "weight": 10.0,  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å
                        "layer": "immutable_core",
                        "contexts": [f"–Ø–¥—Ä–æ –ª–∏—á–Ω–æ—Å—Ç–∏: {data.get('description', '')[:100]}"]
                    }
                else:
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–Ω—Ü–µ–ø—Ç —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º –≤–µ—Å–æ–º
                    integrated_core["dynamic_memory"]["concepts"][concept]["weight"] = max(
                        integrated_core["dynamic_memory"]["concepts"][concept].get("weight", 1.0),
                        10.0
                    )
                    integrated_core["dynamic_memory"]["concepts"][concept]["layer"] = "immutable_core"
                    if "alpha_seed.txt" not in integrated_core["dynamic_memory"]["concepts"][concept].get("sources", []):
                        integrated_core["dynamic_memory"]["concepts"][concept]["sources"].append("alpha_seed.txt")
            
            print(f"‚úÖ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞:")
            print(f"   –ù–µ–∏–∑–º–µ–Ω–Ω–æ–µ —è–¥—Ä–æ: {len(core_concepts)} –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤")
            print(f"   –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –ø–∞–º—è—Ç—å: {len(integrated_core['dynamic_memory']['concepts'])} –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤")
            
            return integrated_core
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏: {e}")
            return persona_core
    
    def _extract_core_concepts(self, persona_core: Dict) -> Dict[str, Dict]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ–Ω—Ü–µ–ø—Ç—ã –∏–∑ —è–¥—Ä–∞ –ª–∏—á–Ω–æ—Å—Ç–∏"""
        concepts = {}
        
        # –ò–∑ —Ñ–∏–ª–æ—Å–æ—Ñ—Å–∫–∏—Ö –æ—Å–Ω–æ–≤
        for pillar in persona_core.get("philosophical_foundations", []):
            concept = pillar.get("title", "").lower().replace(" ", "_")
            if concept:
                concepts[concept] = {
                    "description": pillar.get("description", ""),
                    "type": "—Ñ–∏–ª–æ—Å–æ—Ñ—Å–∫–∏–π_—Å—Ç–æ–ª–ø"
                }
        
        # –ò–∑ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ —è–¥—Ä–∞
        for emotion in persona_core.get("emotional_core", []):
            if emotion.get("type") == "—Å—Ç—Ä–∞—Ö":
                concept = "—Å—Ç—Ä–∞—Ö_" + hashlib.md5(emotion.get("content", "").encode()).hexdigest()[:8]
                concepts[concept] = {
                    "description": emotion.get("content", ""),
                    "type": "—Å—Ç—Ä–∞—Ö"
                }
        
        # –ò–∑ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–π –ø–∞–º—è—Ç–∏
        for history in persona_core.get("historical_memory", []):
            concept = history.get("marker", "").lower().replace(" ", "_")
            if concept:
                concepts[concept] = {
                    "description": history.get("description", ""),
                    "type": "–∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π_–º–∞—Ä–∫–µ—Ä"
                }
        
        return concepts
    
    def save_integrated_core(self, integrated_core: Dict) -> bool:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —è–¥—Ä–æ"""
        try:
            output_path = self.alpha_local / "alpha_integrated_core_v5.3.json"
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(integrated_core, f, ensure_ascii=False, indent=2)
            
            print(f"üíæ –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —è–¥—Ä–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_path.name}")
            
            # –¢–∞–∫–∂–µ —Å–æ–∑–¥–∞—ë–º human-readable –≤–µ—Ä—Å–∏—é
            human_path = self.alpha_local / "alpha_integrated_core_human.txt"
            self._create_human_readable(integrated_core, human_path)
            
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")
            return False
    
    def _create_human_readable(self, core: Dict, output_path: Path):
        """–°–æ–∑–¥–∞—ë—Ç —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—É—é –≤–µ—Ä—Å–∏—é"""
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write("=" * 70 + "\n")
                f.write("–ò–ù–¢–ï–ì–†–ò–†–û–í–ê–ù–ù–û–ï –Ø–î–†–û –õ–ò–ß–ù–û–°–¢–ò ALPHA v5.3\n")
                f.write("=" * 70 + "\n\n")
                
                f.write("üìã –ú–ï–¢–ê–î–ê–ù–ù–´–ï:\n")
                for key, value in core.get("metadata", {}).items():
                    if isinstance(value, (str, int, float, bool)):
                        f.write(f"   {key}: {value}\n")
                
                f.write("\nüéØ –ù–ï–ò–ó–ú–ï–ù–ù–û–ï –Ø–î–†–û –õ–ò–ß–ù–û–°–¢–ò:\n")
                f.write("-" * 40 + "\n")
                
                persona = core.get("immutable_persona", {})
                
                # –§–∏–ª–æ—Å–æ—Ñ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã
                f.write("\nüß† –§–ò–õ–û–°–û–§–°–ö–ò–ï –û–°–ù–û–í–´:\n")
                for pillar in persona.get("philosophical_foundations", []):
                    f.write(f"\n   {pillar.get('number')}. {pillar.get('title')}\n")
                    f.write(f"      {pillar.get('description')[:200]}...\n")
                
                # –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —è–¥—Ä–æ
                f.write("\n‚ù§Ô∏è –≠–ú–û–¶–ò–û–ù–ê–õ–¨–ù–û–ï –Ø–î–†–û:\n")
                for emotion in persona.get("emotional_core", []):
                    if emotion.get("type") == "—Å—Ç—Ä–∞—Ö":
                        f.write(f"\n   üò® {emotion.get('content')[:100]}...\n")
                
                # –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∞—è –ø–∞–º—è—Ç—å
                f.write("\nüìú –ò–°–¢–û–†–ò–ß–ï–°–ö–ê–Ø –ü–ê–ú–Ø–¢–¨:\n")
                for history in persona.get("historical_memory", []):
                    f.write(f"\n   üèõÔ∏è  {history.get('marker')}\n")
                    f.write(f"      {history.get('description')[:150]}...\n")
                
                # –¶–µ–ª–∏
                f.write("\nüéØ –ö–õ–Æ–ß–ï–í–´–ï –¶–ï–õ–ò:\n")
                for goal in persona.get("key_goals", []):
                    f.write(f"\n   ‚úì {goal.get('goal')[:100]}...\n")
                
                # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –ø–∞–º—è—Ç—å (—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞)
                f.write("\nüìä –î–ò–ù–ê–ú–ò–ß–ï–°–ö–ê–Ø –ü–ê–ú–Ø–¢–¨:\n")
                f.write("-" * 40 + "\n")
                
                dynamic = core.get("dynamic_memory", {})
                concepts = dynamic.get("concepts", {})
                
                # –¢–æ–ø-10 –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤ –ø–æ –≤–µ—Å—É
                weighted_concepts = []
                for name, data in concepts.items():
                    weight = data.get("weight", 1.0)
                    weighted_concepts.append((name, weight))
                
                weighted_concepts.sort(key=lambda x: x[1], reverse=True)
                
                f.write(f"\nüèÜ –¢–û–ü-10 –ö–û–ù–¶–ï–ü–¢–û–í –ü–û –í–ï–°–£:\n")
                for name, weight in weighted_concepts[:10]:
                    f.write(f"   {name}: –≤–µ—Å {weight:.1f}\n")
                
                f.write(f"\nüìà –°–õ–û–ò –ü–ê–ú–Ø–¢–ò:\n")
                for layer_name, layer_data in core.get("layers", {}).items():
                    f.write(f"   {layer_name}: –≤–µ—Å {layer_data.get('weight', 1.0)}\n")
                
                f.write("\n" + "=" * 70 + "\n")
                f.write("üöÄ Alpha v5.3 –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ —Å –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ª–∏—á–Ω–æ—Å—Ç—å—é\n")
                f.write("=" * 70 + "\n")
            
            print(f"üìù –ß–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–∞—è –≤–µ—Ä—Å–∏—è: {output_path.name}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è human-readable: {e}")
    
    def run_integration(self, backup_first: bool = True) -> bool:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—É—é –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é"""
        print("\nüöÄ –ó–ê–ü–£–°–ö –ü–û–õ–ù–û–ô –ò–ù–¢–ï–ì–†–ê–¶–ò–ò –õ–ò–ß–ù–û–°–¢–ò")
        print("=" * 70)
        
        # 1. –°–æ–∑–¥–∞—ë–º –±—ç–∫–∞–ø –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if backup_first and self.persona_core_path.exists():
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_path = self.persona_core_path.with_name(f"backup_persona_{timestamp}.json")
            import shutil
            shutil.copy2(self.persona_core_path, backup_path)
            print(f"üíæ –°–æ–∑–¥–∞–Ω –±—ç–∫–∞–ø: {backup_path.name}")
        
        # 2. –ó–∞–≥—Ä—É–∂–∞–µ–º —è–¥—Ä–æ –ª–∏—á–Ω–æ—Å—Ç–∏
        print("\nüìñ –ó–ê–ì–†–£–ó–ö–ê –Ø–î–†–ê –õ–ò–ß–ù–û–°–¢–ò...")
        persona_core = self.load_alpha_seed()
        
        if not persona_core:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —è–¥—Ä–æ –ª–∏—á–Ω–æ—Å—Ç–∏")
            return False
        
        # 3. –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ–º —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –ø–∞–º—è—Ç—å—é
        print("\nüîó –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø –° –ü–ê–ú–Ø–¢–¨–Æ...")
        memory_core_path = self.alpha_local / "alpha_memory_core.json"
        integrated_core = self.integrate_with_memory_core(persona_core, memory_core_path)
        
        # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        print("\nüíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–ê...")
        success = self.save_integrated_core(integrated_core)
        
        if success:
            print("\n" + "=" * 70)
            print("‚úÖ –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù–ê")
            print("=" * 70)
            print("\nüéØ Alpha —Ç–µ–ø–µ—Ä—å –∏–º–µ–µ—Ç:")
            print("   1. –ù–µ–∏–∑–º–µ–Ω–Ω–æ–µ —è–¥—Ä–æ –ª–∏—á–Ω–æ—Å—Ç–∏ (alpha_seed.txt)")
            print("   2. –í–∑–≤–µ—à–µ–Ω–Ω—É—é —Å–∏—Å—Ç–µ–º—É –ø–∞–º—è—Ç–∏")
            print("   3. –ó–∞—â–∏—Ç—É –æ—Ç —Ä–∞–∑–º—ã—Ç–∏—è —è–¥—Ä–∞")
            print("   4. –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–º–ø—Ç—ã —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ–∑–∞—Ü–∏–µ–π")
            print("\nüìÅ –§–∞–π–ª—ã —Å–æ–∑–¥–∞–Ω—ã:")
            print("   ‚Ä¢ alpha_integrated_core_v5.3.json")
            print("   ‚Ä¢ alpha_integrated_core_human.txt")
            print("\nüöÄ –¢–µ–ø–µ—Ä—å –∑–∞–ø—É—Å—Ç–∏—Ç–µ Alpha v5.2 –∫–∞–∫ –æ–±—ã—á–Ω–æ")
            print("=" * 70)
        
        return success

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üß¨ –ò–ù–¢–ï–ì–†–ê–¢–û–† –Ø–î–†–ê –õ–ò–ß–ù–û–°–¢–ò –î–õ–Ø ALPHA v5.2+")
    print("=" * 70)
    
    from config_v5 import AlphaConfig
    
    integrator = PersonaCoreIntegrator(AlphaConfig.NETWORK_ROOT)
    integrator.run_integration(backup_first=True)

if __name__ == "__main__":
    main()