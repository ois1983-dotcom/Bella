"""
–ì–õ–ê–í–ù–´–ô –ú–ï–ù–ï–î–ñ–ï–† –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–ê–õ–¨–ù–û–ì–û –ö–û–î–ê v1.1
–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å–∞–º–æ–ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏—è —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º–∏ –ª–∏–º–∏—Ç–∞–º–∏
"""

import ast
import json
import shutil
import hashlib
import time
import threading
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import fnmatch

class ExperimentalCodeManager:
    """
    –£–ü–†–û–©–ï–ù–ù–´–ô –ò –ë–ï–ó–û–ü–ê–°–ù–´–ô –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Å–∞–º–æ–ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏—è –∫–æ–¥–∞
    –†–∞–±–æ—Ç–∞–µ—Ç –¢–û–õ–¨–ö–û —Å experimental_*.py —Ñ–∞–π–ª–∞–º–∏
    –í–ï–†–°–ò–Ø 1.1: –£–≤–µ–ª–∏—á–µ–Ω—ã –ª–∏–º–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–æ–ª—å—à–∏–º–∏ —Ñ–∞–π–ª–∞–º–∏
    """
    
    def __init__(self, security_core, alpha_local_path: Path):
        self.security = security_core
        self.alpha_local = alpha_local_path
        self.alpha_v5 = alpha_local_path.parent / "alpha_v5"
        
        # –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ –∫–æ–¥–∞
        self.experimental_dir = self.alpha_v5 / "experimental"
        self.experimental_dir.mkdir(exist_ok=True)
        
        # –ù–ê–°–¢–†–û–ô–ö–ò –î–õ–Ø –ë–û–õ–¨–®–ò–• –§–ê–ô–õ–û–í (–ò–ó–ú–ï–ù–ï–ù–û)
        self.max_file_size_lines = 2000  # –ë—ã–ª–æ 100, —Ç–µ–ø–µ—Ä—å 2000 —Å—Ç—Ä–æ–∫
        self.max_function_lines = 100    # –ë—ã–ª–æ 30, —Ç–µ–ø–µ—Ä—å 100 —Å—Ç—Ä–æ–∫
        self.max_nested_loops = 5        # –ë—ã–ª–æ 3, —Ç–µ–ø–µ—Ä—å 5 —É—Ä–æ–≤–Ω–µ–π
        
        # –°–æ–∑–¥–∞—ë–º –±–∞–∑–æ–≤—ã–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
        self._create_base_experimental_file()
        
        # –ñ—É—Ä–Ω–∞–ª –∏–∑–º–µ–Ω–µ–Ω–∏–π
        self.change_log = self.alpha_local / "experimental_changes.json"
        self._init_change_log()
        
        # –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤
        self.file_locks = {}
        self.lock_timeout = 30  # —Å–µ–∫—É–Ω–¥
        
        # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤
        self.max_backups = 10  # –ë—ã–ª–æ 5, —Ç–µ–ø–µ—Ä—å 10
        self._clean_old_backups()
        
        print(f">> ExperimentalCodeManager v1.1 –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        print(f">> –†–∞–±–æ—á–∞—è –ø–∞–ø–∫–∞: {self.experimental_dir}")
        print(f">> –ú–∞–∫—Å. —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {self.max_file_size_lines} —Å—Ç—Ä–æ–∫")
        print(f">> –ú–∞–∫—Å. —Ñ—É–Ω–∫—Ü–∏—è: {self.max_function_lines} —Å—Ç—Ä–æ–∫")
        print(f">> –ú–∞–∫—Å. –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç—å —Ü–∏–∫–ª–æ–≤: {self.max_nested_loops} —É—Ä–æ–≤–Ω–µ–π")
    
    def _create_base_experimental_file(self):
        """–°–æ–∑–¥–∞—ë—Ç –±–∞–∑–æ–≤—ã–π experimental —Ñ–∞–π–ª –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç"""
        base_file = self.experimental_dir / "experimental_base.py"
        if not base_file.exists():
            base_content = '''"""
–≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–ê–õ–¨–ù–´–ô –§–ê–ô–õ –î–õ–Ø –°–ê–ú–û–ü–ï–†–ï–ü–ò–°–´–í–ê–ù–ò–Ø v1.1
Alpha v5.4 –º–æ–∂–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ –∏–∑–º–µ–Ω—è—Ç—å —ç—Ç–æ—Ç —Ñ–∞–π–ª
"""

def experimental_function():
    """–ü—Ä–∏–º–µ—Ä —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ —É–ª—É—á—à–µ–Ω–∏—è"""
    return "–≠—Ç–æ experimental –∫–æ–¥, –∫–æ—Ç–æ—Ä—ã–π Alpha –º–æ–∂–µ—Ç –∏–∑–º–µ–Ω—è—Ç—å"

def get_experimental_status():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ –∫–æ–¥–∞"""
    return {
        "status": "active",
        "version": "1.1",
        "last_modified": "2025-01-09",
        "purpose": "–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Å–∞–º–æ–ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏–µ –∫–æ–¥–∞ Alpha"
    }

# Alpha –º–æ–∂–µ—Ç –¥–æ–±–∞–≤–ª—è—Ç—å —Å—é–¥–∞ –Ω–æ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∏ —É–ª—É—á—à–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ
'''
            with open(base_file, 'w', encoding='utf-8') as f:
                f.write(base_content)
            print(f">> –°–æ–∑–¥–∞–Ω –±–∞–∑–æ–≤—ã–π experimental —Ñ–∞–π–ª: {base_file.name}")
    
    def _init_change_log(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∂—É—Ä–Ω–∞–ª –∏–∑–º–µ–Ω–µ–Ω–∏–π"""
        if not self.change_log.exists():
            with open(self.change_log, 'w', encoding='utf-8') as f:
                json.dump({
                    "changes": [],
                    "metadata": {
                        "created": datetime.now().isoformat(),
                        "max_entries": 100,  # –ë—ã–ª–æ 50
                        "purpose": "–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π experimental –∫–æ–¥–∞",
                        "version": "1.1"
                    }
                }, f, indent=2)
    
    def _clean_old_backups(self):
        """–û—á–∏—â–∞–µ—Ç —Å—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N"""
        backup_dir = self.alpha_local / "code_backups"
        if not backup_dir.exists():
            return
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –±—ç–∫–∞–ø—ã
        backups = list(backup_dir.glob("checkpoint_*"))
        backups.sort(key=lambda x: x.stat().st_mtime)
        
        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ, –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ max_backups
        if len(backups) > self.max_backups:
            for backup in backups[:-self.max_backups]:
                try:
                    shutil.rmtree(backup)
                    print(f">> –£–¥–∞–ª—ë–Ω —Å—Ç–∞—Ä—ã–π –±—ç–∫–∞–ø: {backup.name}")
                except:
                    pass
    
    def _acquire_file_lock(self, filename: str) -> bool:
        """–ü–æ–ª—É—á–∞–µ—Ç –±–ª–æ–∫–∏—Ä–æ–≤–∫—É —Ñ–∞–π–ª–∞"""
        lock_file = self.experimental_dir / f".{filename}.lock"
        
        if lock_file.exists():
            lock_age = time.time() - lock_file.stat().st_mtime
            if lock_age > self.lock_timeout:
                lock_file.unlink(missing_ok=True)
            else:
                return False
        
        try:
            with open(lock_file, 'w') as f:
                f.write(str(datetime.now().isoformat()))
            self.file_locks[filename] = lock_file
            return True
        except:
            return False
    
    def _release_file_lock(self, filename: str):
        """–û—Å–≤–æ–±–æ–∂–¥–∞–µ—Ç –±–ª–æ–∫–∏—Ä–æ–≤–∫—É —Ñ–∞–π–ª–∞"""
        if filename in self.file_locks:
            lock_file = self.file_locks[filename]
            lock_file.unlink(missing_ok=True)
            del self.file_locks[filename]
    
    def create_safe_checkpoint(self) -> Optional[str]:
        """–°–æ–∑–¥–∞—ë—Ç –±–µ–∑–æ–ø–∞—Å–Ω—ã–π checkpoint (—Ç–æ–ª—å–∫–æ experimental —Ñ–∞–π–ª—ã)"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            checkpoint_dir = self.alpha_local / "code_backups" / f"experimental_checkpoint_{timestamp}"
            checkpoint_dir.mkdir(parents=True, exist_ok=True)
            
            experimental_files = list(self.experimental_dir.glob("*.py"))
            
            for file in experimental_files:
                shutil.copy2(file, checkpoint_dir / file.name)
            
            metadata = {
                "timestamp": datetime.now().isoformat(),
                "type": "experimental_checkpoint",
                "files": [f.name for f in experimental_files],
                "total_size": sum(f.stat().st_size for f in experimental_files),
                "purpose": "–ê–≤—Ç–æ–Ω–æ–º–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –ø–µ—Ä–µ–¥ –∏–∑–º–µ–Ω–µ–Ω–∏–µ–º –∫–æ–¥–∞",
                "version": "1.1"
            }
            
            with open(checkpoint_dir / "metadata.json", 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2)
            
            print(f">> –°–æ–∑–¥–∞–Ω –±–µ–∑–æ–ø–∞—Å–Ω—ã–π checkpoint: {checkpoint_dir.name}")
            
            self._clean_old_backups()
            
            return checkpoint_dir.name
            
        except Exception as e:
            print(f">> –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è checkpoint: {e}")
            return None
    
    def analyze_experimental_code_safely(self) -> List[Dict]:
        """
        –ê–ù–ê–õ–ò–ó–ò–†–£–ï–¢ –ö–û–î –ë–ï–ó –õ–û–ñ–ù–´–• –°–†–ê–ë–ê–¢–´–í–ê–ù–ò–ô v1.1
        –° —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º–∏ –ª–∏–º–∏—Ç–∞–º–∏ –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
        """
        suggestions = []
        
        for py_file in self.experimental_dir.glob("*.py"):
            if not self._acquire_file_lock(py_file.name):
                continue
            
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    code = f.read()
                
                issues = self._analyze_with_ast(code, py_file.name)
                
                if issues:
                    for issue in issues:
                        suggestion = {
                            "filename": py_file.name,
                            "line": issue.get("line", 0),
                            "issue_type": issue["type"],
                            "description": issue["description"],
                            "priority": self._calculate_priority(issue),
                            "code_snippet": issue.get("code_snippet", "")[:150]  # –£–≤–µ–ª–∏—á–µ–Ω–æ
                        }
                        
                        if not self._is_false_positive(suggestion):
                            suggestions.append(suggestion)
                
                # –ü–†–û–í–ï–†–ö–ê –†–ê–ó–ú–ï–†–ê –§–ê–ô–õ–ê (–° –£–í–ï–õ–ò–ß–ï–ù–ù–´–ú –õ–ò–ú–ò–¢–û–ú)
                metrics = self._calculate_code_metrics(code)
                
                if metrics["line_count"] > self.max_file_size_lines:
                    suggestions.append({
                        "filename": py_file.name,
                        "issue_type": "file_too_large",
                        "description": f"–§–∞–π–ª –æ—á–µ–Ω—å –±–æ–ª—å—à–æ–π ({metrics['line_count']} —Å—Ç—Ä–æ–∫)",
                        "priority": 3,  # –ü–æ–Ω–∏–∂–µ–Ω –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç, —Ç–∞–∫ –∫–∞–∫ –ª–∏–º–∏—Ç –≤—ã—Å–æ–∫–∏–π
                        "suggestion": "–†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –º–æ–¥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ –ø—Ä–∏ >5000 —Å—Ç—Ä–æ–∫"
                    })
                
                if metrics["comment_ratio"] < 0.05:  # 5% –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –º–∏–Ω–∏–º—É–º
                    suggestions.append({
                        "filename": py_file.name,
                        "issue_type": "low_comments",
                        "description": f"–ú–∞–ª–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ ({metrics['comment_ratio']:.1%})",
                        "priority": 4,
                        "suggestion": "–î–æ–±–∞–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é"
                    })
                    
            finally:
                self._release_file_lock(py_file.name)
        
        suggestions.sort(key=lambda x: x["priority"], reverse=True)
        return suggestions[:7]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–æ–ª—å—à–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
    
    def _analyze_with_ast(self, code: str, filename: str) -> List[Dict]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–¥ —Å –ø–æ–º–æ—â—å—é AST (—Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º–∏ –ª–∏–º–∏—Ç–∞–º–∏)"""
        issues = []
        
        try:
            tree = ast.parse(code)
            
            # –£–°–¢–ê–ù–û–í–õ–ï–ù–û –°–í–Ø–ó–´–í–ê–ù–ò–ï –†–û–î–ò–¢–ï–õ–ï–ô –î–õ–Ø –£–ó–õ–û–í
            for node in ast.walk(tree):
                for child in ast.iter_child_nodes(node):
                    child.parent = node
            
            for node in ast.walk(tree):
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≥–ª—É–±–æ–∫—É—é –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç—å —Ü–∏–∫–ª–æ–≤ (—É–≤–µ–ª–∏—á–µ–Ω –ª–∏–º–∏—Ç)
                if isinstance(node, (ast.For, ast.While)):
                    nested_count = self._count_nested_loops(node)
                    if nested_count >= self.max_nested_loops:
                        issues.append({
                            "type": "nested_loops",
                            "description": f"–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö —Ü–∏–∫–ª–æ–≤ ({nested_count} —É—Ä–æ–≤–Ω—è)",
                            "line": node.lineno,
                            "code_snippet": ast.get_source_segment(code, node)[:200]
                        })
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥–ª–∏–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ (—É–≤–µ–ª–∏—á–µ–Ω –ª–∏–º–∏—Ç)
                if isinstance(node, ast.FunctionDef):
                    function_length = len(node.body)
                    if function_length > self.max_function_lines:
                        issues.append({
                            "type": "long_function",
                            "description": f"–§—É–Ω–∫—Ü–∏—è —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–∞—è ({function_length} —Å—Ç—Ä–æ–∫)",
                            "line": node.lineno,
                            "function_name": node.name
                        })
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–ª–æ–∂–Ω—ã–µ —É—Å–ª–æ–≤–∏—è
                if isinstance(node, ast.If):
                    condition_complexity = self._calculate_condition_complexity(node.test)
                    if condition_complexity >= 5:  # –£–≤–µ–ª–∏—á–µ–Ω –ª–∏–º–∏—Ç
                        issues.append({
                            "type": "complex_condition",
                            "description": f"–°–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω–æ–µ —É—Å–ª–æ–≤–∏–µ ({condition_complexity} –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤)",
                            "line": node.lineno
                        })
            
        except SyntaxError as e:
            issues.append({
                "type": "syntax_error",
                "description": f"–°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e.msg}",
                "line": e.lineno
            })
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞
        duplicate_issues = self._check_duplicate_code(code)
        issues.extend(duplicate_issues)
        
        return issues
    
    def _count_nested_loops(self, node) -> int:
        """–°—á–∏—Ç–∞–µ—Ç —É—Ä–æ–≤–µ–Ω—å –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏ —Ü–∏–∫–ª–æ–≤ (—Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ)"""
        count = 0
        for child in ast.walk(node):
            if isinstance(child, (ast.For, ast.While)):
                if hasattr(child, 'parent') and child.parent == node:
                    count = max(count, 1 + self._count_nested_loops(child))
        return count
    
    def _calculate_condition_complexity(self, node) -> int:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç—å —É—Å–ª–æ–≤–∏—è"""
        if isinstance(node, ast.BoolOp):
            return len(node.values)
        elif isinstance(node, ast.Compare):
            return 1 + len(node.ops)
        elif isinstance(node, ast.UnaryOp):
            return 1 + self._calculate_condition_complexity(node.operand)
        elif isinstance(node, (ast.BinOp, ast.Call, ast.Attribute)):
            return 1
        else:
            return 0
    
    def _check_duplicate_code(self, code: str) -> List[Dict]:
        """–û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞ –≤ —Ñ–∞–π–ª–µ"""
        issues = []
        lines = code.split('\n')
        
        # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
        code_lines = []
        for i, line in enumerate(lines):
            stripped = line.strip()
            if stripped and not stripped.startswith('#') and not stripped.startswith('"""'):
                normalized = ' '.join(stripped.split())
                code_lines.append((i, normalized))
        
        # –ò—â–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–∑ 4+ —Å—Ç—Ä–æ–∫ (–±—ã–ª–æ 3)
        sequence_length = 4
        for i in range(len(code_lines) - sequence_length):
            seq_indices = [code_lines[j][0] for j in range(i, i + sequence_length)]
            seq_text = [code_lines[j][1] for j in range(i, i + sequence_length)]
            
            for j in range(i + sequence_length, len(code_lines) - sequence_length):
                match_seq = [code_lines[k][1] for k in range(j, j + sequence_length)]
                
                if seq_text == match_seq:
                    issues.append({
                        "type": "duplicate_code",
                        "description": f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞ ({sequence_length} –∏–¥–µ–Ω—Ç–∏—á–Ω—ã—Ö —Å—Ç—Ä–æ–∫)",
                        "line": seq_indices[0] + 1,
                        "code_snippet": '; '.join(seq_text)[:150],
                        "duplicate_at": code_lines[j][0] + 1
                    })
                    break
        
        return issues
    
    def _calculate_code_metrics(self, code: str) -> Dict:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –±–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–æ–¥–∞"""
        lines = code.split('\n')
        total_lines = len(lines)
        
        comment_lines = sum(1 for line in lines if line.strip().startswith('#'))
        empty_lines = sum(1 for line in lines if not line.strip())
        code_lines = total_lines - comment_lines - empty_lines
        
        return {
            "line_count": total_lines,
            "code_lines": code_lines,
            "comment_lines": comment_lines,
            "empty_lines": empty_lines,
            "comment_ratio": comment_lines / code_lines if code_lines > 0 else 0
        }
    
    def _calculate_priority(self, issue: Dict) -> int:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã"""
        priority_map = {
            "syntax_error": 10,
            "nested_loops": 6,  # –ü–æ–Ω–∏–∂–µ–Ω –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç (–±—ã–ª–æ 8)
            "long_function": 5,  # –ü–æ–Ω–∏–∂–µ–Ω (–±—ã–ª–æ 6)
            "complex_condition": 4,  # –ü–æ–Ω–∏–∂–µ–Ω (–±—ã–ª–æ 5)
            "file_too_large": 3,  # –°–∏–ª—å–Ω–æ –ø–æ–Ω–∏–∂–µ–Ω (–±—ã–ª–æ 7)
            "low_comments": 3,
            "duplicate_code": 4
        }
        
        return priority_map.get(issue["type"], 5)
    
    def _is_false_positive(self, suggestion: Dict) -> bool:
        """–§–∏–ª—å—Ç—Ä—É–µ—Ç –ª–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è"""
        issue_type = suggestion["issue_type"]
        code_snippet = suggestion.get("code_snippet", "").lower()
        filename = suggestion.get("filename", "").lower()
        
        # –§–∞–π–ª—ã —Å "integrator" –º–æ–≥—É—Ç –±—ã—Ç—å –±–æ–ª—å—à–∏–º–∏ - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ
        if "integrator" in filename and issue_type == "file_too_large":
            return True
        
        # –ë–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã experimental - —ç—Ç–æ –æ–∂–∏–¥–∞–µ–º–æ
        if "experimental" in filename and issue_type == "file_too_large":
            lines = suggestion.get("description", "")
            if "5000" not in lines:  # –ï—Å–ª–∏ –º–µ–Ω—å—à–µ 5000 —Å—Ç—Ä–æ–∫ - –Ω–æ—Ä–º–∞–ª—å–Ω–æ
                return True
        
        if issue_type == "nested_loops":
            if "for i in range" in code_snippet and "for j in range" in code_snippet:
                return True
        
        if issue_type == "complex_condition":
            if "is not none" in code_snippet or "isinstance" in code_snippet:
                return True
        
        if issue_type == "duplicate_code":
            if all(word in code_snippet.lower() for word in ['print', 'test', 'debug']):
                return True
        
        return False
    
    def apply_safe_improvement(self, suggestion: Dict) -> Dict:
        """
        –ü–†–ò–ú–ï–ù–Ø–ï–¢ –ë–ï–ó–û–ü–ê–°–ù–û–ï –£–õ–£–ß–®–ï–ù–ò–ï v1.1
        –° —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
        """
        result = {
            "success": False,
            "filename": suggestion["filename"],
            "action": "code_improvement",
            "timestamp": datetime.now().isoformat(),
            "error": None,
            "backup_created": False,
            "changes_made": []
        }
        
        filename = suggestion["filename"]
        filepath = self.experimental_dir / filename
        
        if not filepath.exists():
            result["error"] = f"–§–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {filename}"
            return result
        
        if not self._acquire_file_lock(filename):
            result["error"] = "–§–∞–π–ª –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –¥—Ä—É–≥–∏–º –ø—Ä–æ—Ü–µ—Å—Å–æ–º"
            return result
        
        try:
            checkpoint_id = self.create_safe_checkpoint()
            if checkpoint_id:
                result["backup_created"] = True
                result["checkpoint_id"] = checkpoint_id
            
            with open(filepath, 'r', encoding='utf-8') as f:
                current_code = f.read()
            
            new_code = current_code
            change_applied = False
            
            issue_type = suggestion["issue_type"]
            
            if issue_type == "low_comments":
                new_code = self._add_smart_comments(current_code)
                result["changes_made"].append("–î–æ–±–∞–≤–ª–µ–Ω—ã –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏")
                change_applied = True
            
            elif issue_type == "long_function" and "function_name" in suggestion:
                func_name = suggestion["function_name"]
                new_code = self._split_long_function(current_code, func_name)
                result["changes_made"].append(f"–†–∞–∑–¥–µ–ª–µ–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—è {func_name}")
                change_applied = True
            
            elif issue_type == "duplicate_code":
                new_code = self._remove_duplicate_code(current_code)
                result["changes_made"].append("–£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞")
                change_applied = True
            
            elif issue_type == "file_too_large":
                # –î–õ–Ø –ë–û–õ–¨–®–ò–• –§–ê–ô–õ–û–í - –¢–û–õ–¨–ö–û –î–û–ë–ê–í–õ–Ø–ï–ú –ö–û–ú–ú–ï–ù–¢–ê–†–ò–ô, –ù–ï –†–ê–ó–ë–ò–í–ê–ï–ú
                new_code = self._add_large_file_header(current_code, suggestion)
                result["changes_made"].append("–î–æ–±–∞–≤–ª–µ–Ω –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è –±–æ–ª—å—à–æ–≥–æ —Ñ–∞–π–ª–∞")
                change_applied = True
            
            # –ï—Å–ª–∏ –Ω–µ –±—ã–ª–æ —Ä–µ–∞–ª—å–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π
            if not change_applied or new_code == current_code:
                # –î–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —É—Å–ø–µ—Ö
                if issue_type == "file_too_large":
                    result["success"] = True
                    result["changes_made"] = ["–§–∞–π–ª –±–æ–ª—å—à–æ–π, –Ω–æ –±–µ–∑–æ–ø–∞—Å–µ–Ω"]
                    return result
                else:
                    result["error"] = "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–º–µ–Ω–∏—Ç—å —É–ª—É—á—à–µ–Ω–∏–µ"
                    return result
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–æ–≤–æ–≥–æ –∫–æ–¥–∞
            validation = self._validate_python_code(new_code)
            if not validation["valid"]:
                result["error"] = f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {validation['error']}"
                return result
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(new_code)
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º
            test_result = self._test_experimental_code(filename)
            if not test_result["success"]:
                result["error"] = f"–¢–µ—Å—Ç –Ω–µ –ø—Ä–æ–π–¥–µ–Ω: {test_result['error']}"
                
                if checkpoint_id:
                    self._restore_from_checkpoint(checkpoint_id)
                
                return result
            
            result["success"] = True
            result["validation"] = validation
            result["test_result"] = test_result
            
            self._log_change(suggestion, result)
            
            return result
            
        except Exception as e:
            result["error"] = f"–ò—Å–∫–ª—é—á–µ–Ω–∏–µ: {str(e)}"
            return result
            
        finally:
            self._release_file_lock(filename)
    
    def _add_large_file_header(self, code: str, suggestion: Dict) -> str:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ (–±–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è)"""
        lines = code.split('\n')
        
        # –ò—â–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
        header_added = False
        for i, line in enumerate(lines[:5]):
            if line.strip().startswith("# –ë–û–õ–¨–®–û–ô –§–ê–ô–õ:"):
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
                lines[i] = f"# –ë–û–õ–¨–®–û–ô –§–ê–ô–õ: {suggestion['description']} - –û–±–Ω–æ–≤–ª–µ–Ω–æ {datetime.now().strftime('%Y-%m-%d %H:%M')}"
                header_added = True
                break
        
        if not header_added:
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –ø–æ—Å–ª–µ –ø–µ—Ä–≤—ã—Ö —Å—Ç—Ä–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
            insert_pos = 0
            for i, line in enumerate(lines):
                if not line.strip().startswith('"""') and not line.strip().startswith('#'):
                    insert_pos = i
                    break
            
            large_file_comment = f"""# –ë–û–õ–¨–®–û–ô –§–ê–ô–õ: {suggestion['description']}
# –°–∏—Å—Ç–µ–º–∞ —Å–∞–º–æ–ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏—è –æ–±–Ω–∞—Ä—É–∂–∏–ª–∞, —á—Ç–æ —ç—Ç–æ—Ç —Ñ–∞–π–ª –±–æ–ª—å—à–æ–π.
# –≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ç–æ—Ä–æ–≤ –∏ —Å–ª–æ–∂–Ω—ã—Ö –º–æ–¥—É–ª–µ–π.
# –ü–æ—Å–ª–µ–¥–Ω—è—è –ø—Ä–æ–≤–µ—Ä–∫–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
            lines.insert(insert_pos, large_file_comment)
        
        return '\n'.join(lines)
    
    def _add_smart_comments(self, code: str) -> str:
        """–î–æ–±–∞–≤–ª—è–µ—Ç —É–º–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏"""
        lines = code.split('\n')
        
        for i, line in enumerate(lines):
            if line.strip().startswith('def ') and i + 1 < len(lines):
                next_line = lines[i + 1].strip()
                if not next_line.startswith('"""') and not next_line.startswith('#'):
                    func_name = line.split('def ')[1].split('(')[0]
                    comment = f'    """–§—É–Ω–∫—Ü–∏—è {func_name}"""'
                    lines.insert(i + 1, comment)
        
        return '\n'.join(lines)
    
    def _split_long_function(self, code: str, func_name: str) -> str:
        """–†–∞–∑–¥–µ–ª—è–µ—Ç –¥–ª–∏–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –Ω–∞ —á–∞—Å—Ç–∏"""
        lines = code.split('\n')
        
        for i, line in enumerate(lines):
            if f'def {func_name}' in line:
                todo_comment = f'    # TODO: –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ –¥–ª–∏–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏'
                if i + 1 < len(lines):
                    lines.insert(i + 1, todo_comment)
                break
        
        return '\n'.join(lines)
    
    def _remove_duplicate_code(self, code: str) -> str:
        """–£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏—Ä—É—é—â–∏–π—Å—è –∫–æ–¥"""
        lines = code.split('\n')
        seen_lines = []
        result_lines = []
        
        for line in lines:
            stripped = line.strip()
            if stripped and not stripped.startswith('#') and not stripped.startswith('"""'):
                normalized = ' '.join(stripped.split())
                
                if normalized not in seen_lines:
                    seen_lines.append(normalized)
                    result_lines.append(line)
                else:
                    result_lines.append(f"# –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —É–¥–∞–ª–µ–Ω–æ: {stripped[:80]}...")
            else:
                result_lines.append(line)
        
        return '\n'.join(result_lines)
    
    def _validate_python_code(self, code: str) -> Dict:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç Python –∫–æ–¥"""
        try:
            ast.parse(code)
            return {"valid": True, "error": None}
        except SyntaxError as e:
            return {"valid": False, "error": f"–°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e.msg}"}
    
    def _test_experimental_code(self, filename: str) -> Dict:
        """–ü—Ä–æ—Å—Ç–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ experimental –∫–æ–¥–∞"""
        try:
            import importlib.util
            import sys
            
            filepath = self.experimental_dir / filename
            spec = importlib.util.spec_from_file_location(
                f"experimental_{filename.replace('.py', '')}",
                filepath
            )
            
            if spec is None:
                return {"success": False, "error": "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—é"}
            
            module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(module)
            
            if hasattr(module, 'experimental_function'):
                try:
                    result = module.experimental_function()
                    if not isinstance(result, str):
                        return {"success": False, "error": "–§—É–Ω–∫—Ü–∏—è –≤–µ—Ä–Ω—É–ª–∞ –Ω–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø"}
                except:
                    return {"success": False, "error": "–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏"}
            
            return {"success": True, "error": None}
            
        except Exception as e:
            return {"success": False, "error": f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {str(e)}"}
    
    def _restore_from_checkpoint(self, checkpoint_id: str) -> bool:
        """–í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∏–∑ checkpoint"""
        try:
            checkpoint_dir = self.alpha_local / "code_backups" / checkpoint_id
            if not checkpoint_dir.exists():
                return False
            
            for py_file in checkpoint_dir.glob("*.py"):
                if py_file.name != "metadata.json":
                    target_file = self.experimental_dir / py_file.name
                    shutil.copy2(py_file, target_file)
            
            print(f">> –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –∏–∑ checkpoint: {checkpoint_id}")
            return True
            
        except:
            return False
    
    def _log_change(self, suggestion: Dict, result: Dict):
        """–õ–æ–≥–∏—Ä—É–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–µ"""
        try:
            with open(self.change_log, 'r', encoding='utf-8') as f:
                log_data = json.load(f)
            
            log_entry = {
                "timestamp": datetime.now().isoformat(),
                "suggestion": suggestion,
                "result": result,
                "status": "success" if result["success"] else "failed"
            }
            
            log_data["changes"].append(log_entry)
            
            if len(log_data["changes"]) > 100:
                log_data["changes"] = log_data["changes"][-100:]
            
            with open(self.change_log, 'w', encoding='utf-8') as f:
                json.dump(log_data, f, indent=2)
                
        except Exception as e:
            print(f">> –û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
    
    def get_status(self) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å –º–µ–Ω–µ–¥–∂–µ—Ä–∞ v1.1"""
        experimental_files = list(self.experimental_dir.glob("*.py"))
        
        return {
            "status": "active",
            "version": "1.1",
            "experimental_dir": str(self.experimental_dir),
            "experimental_files": [f.name for f in experimental_files],
            "file_count": len(experimental_files),
            "max_backups": self.max_backups,
            "lock_timeout": self.lock_timeout,
            "safety_level": "high",
            "max_file_size_lines": self.max_file_size_lines,
            "max_function_lines": self.max_function_lines,
            "max_nested_loops": self.max_nested_loops,
            "detection_capabilities": [
                "–°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏",
                f"–í–ª–æ–∂–µ–Ω–Ω—ã–µ —Ü–∏–∫–ª—ã (>{self.max_nested_loops} —É—Ä–æ–≤–Ω–µ–π)",
                f"–î–ª–∏–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ (>{self.max_function_lines} —Å—Ç—Ä–æ–∫)",
                f"–°–ª–æ–∂–Ω—ã–µ —É—Å–ª–æ–≤–∏—è (>4 –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤)",
                f"–î—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞ (4+ –∏–¥–µ–Ω—Ç–∏—á–Ω—ã—Ö —Å—Ç—Ä–æ–∫)",
                f"–§–∞–π–ª—ã >{self.max_file_size_lines} —Å—Ç—Ä–æ–∫",
                "–ù–∏–∑–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ (<5%)"
            ],
            "restrictions": [
                "–¢–æ–ª—å–∫–æ experimental_*.py —Ñ–∞–π–ª—ã",
                "AST-–∞–Ω–∞–ª–∏–∑ –≤–º–µ—Å—Ç–æ regex",
                "–ë–ª–æ–∫–∏—Ä–æ–≤–∫–∏ —Ñ–∞–π–ª–æ–≤",
                "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –±—ç–∫–∞–ø—ã",
                "–í–∞–ª–∏–¥–∞—Ü–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ",
                "–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π"
            ]
        }

# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
if __name__ == "__main__":
    print("üß™ –¢–µ—Å—Ç ExperimentalCodeManager v1.1...")
    
    class MockSecurity:
        def validate_action(self, *args, **kwargs):
            return True, "–†–∞–∑—Ä–µ—à–µ–Ω–æ", {}
    
    test_dir = Path("test_experimental")
    test_dir.mkdir(exist_ok=True)
    
    manager = ExperimentalCodeManager(MockSecurity(), test_dir)
    
    suggestions = manager.analyze_experimental_code_safely()
    print(f">> –ù–∞–π–¥–µ–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {len(suggestions)}")
    
    status = manager.get_status()
    print(f">> –í–µ—Ä—Å–∏—è: {status['version']}")
    print(f">> –ú–∞–∫—Å. —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {status['max_file_size_lines']} —Å—Ç—Ä–æ–∫")
    
    import shutil
    shutil.rmtree(test_dir, ignore_errors=True)
    
    print("‚úÖ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à—ë–Ω")